from __future__ import annotations

import os
import io
import base64
from datetime import datetime, timezone, date
from pathlib import Path
from typing import Optional

import numpy as np
import pandas as pd
import requests
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
try:
    # Kaggle is optional; only import if installed
    from kaggle import api as kaggle_api  # type: ignore
    KAGGLE_AVAILABLE = True
except Exception:
    kaggle_api = None  # type: ignore
    KAGGLE_AVAILABLE = False


# -----------------------------
# í°íŠ¸ ì ìš© ì‹œë„ (ì—†ìœ¼ë©´ ìë™ ìƒëµ)
# -----------------------------
def apply_pretendard_font():
    candidates = [
        os.path.join("fonts", "Pretendard-Bold.ttf"),
        os.path.join(os.sep, "fonts", "Pretendard-Bold.ttf"),
        "Pretendard-Bold.ttf",
    ]
    font_path = next((p for p in candidates if os.path.exists(p)), None)
    if font_path:
        try:
            with open(font_path, "rb") as f:
                b64 = base64.b64encode(f.read()).decode("utf-8")
            st.markdown(
                f"""
                <style>
                @font-face {{
                  font-family: 'Pretendard';
                  src: url(data:font/ttf;base64,{b64}) format('truetype');
                  font-weight: 700;
                  font-style: normal;
                }}
                html, body, [class*="css"] {{
                  font-family: 'Pretendard', -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Noto Sans KR', 'Apple SD Gothic Neo', 'ë§‘ì€ ê³ ë”•', 'Malgun Gothic', 'Nanum Gothic', sans-serif;
                }}
                </style>
                """,
                unsafe_allow_html=True,
            )
        except Exception:
            pass
    # Plotly ì „ì—­ í°íŠ¸ ì„¤ì •(ë¸Œë¼ìš°ì € í°íŠ¸ ìš°ì„ )
    # ì „ì—­ í…œí”Œë¦¿ ì„¤ì •ì€ í™˜ê²½ì— ë”°ë¼ ì œì•½ì´ ìˆì–´, ê° figure ìˆ˜ì¤€ì—ì„œ update_layout(font=...)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    return


# -----------------------------
# ê³µí†µ ìœ í‹¸
# -----------------------------
st.set_page_config(page_title="ê¸°í›„Â·í•™ìŠµ ê³µê°œ ë°ì´í„° & ì‚¬ìš©ì ì„¤ëª… ëŒ€ì‹œë³´ë“œ", layout="wide")
apply_pretendard_font()


def today_utc_date() -> date:
    return datetime.now(timezone.utc).date()


def drop_future(df: pd.DataFrame, date_col: str = "date") -> pd.DataFrame:
    today = today_utc_date()
    out = df.copy()
    out[date_col] = pd.to_datetime(out[date_col]).dt.date
    return out[out[date_col] <= today]


@st.cache_data(ttl=60 * 60)
def robust_get(url: str, params: Optional[dict] = None, retry: int = 3, timeout: int = 30) -> requests.Response:
    last_err: Optional[Exception] = None
    for _ in range(retry):
        try:
            r = requests.get(url, params=params, timeout=timeout)
            if r.status_code == 200:
                return r
            last_err = RuntimeError(f"HTTP {r.status_code}")
        except Exception as e:
            last_err = e
    raise RuntimeError(f"ìš”ì²­ ì‹¤íŒ¨: {url} ({last_err})")


# -----------------------------
# Kaggle ìœ í‹¸
# -----------------------------
def kaggle_authenticate_if_possible() -> bool:
    if not KAGGLE_AVAILABLE:
        return False
    # Prefer config dir created by app or repo Kaggle.json
    config_dir = os.path.join(os.getcwd(), ".kaggle")
    repo_kaggle = os.path.join(os.getcwd(), "Kaggle.json")
    os.makedirs(config_dir, exist_ok=True)
    config_path = os.path.join(config_dir, "kaggle.json")
    if os.path.exists(repo_kaggle) and not os.path.exists(config_path):
        try:
            with open(repo_kaggle, "rb") as src, open(config_path, "wb") as dst:
                dst.write(src.read())
            try:
                os.chmod(config_path, 0o600)
            except Exception:
                pass
            os.environ["KAGGLE_CONFIG_DIR"] = config_dir
        except Exception:
            pass
    # Try to authenticate
    try:
        kaggle_api.authenticate()  # type: ignore[attr-defined]
        return True
    except Exception:
        return bool(os.getenv("KAGGLE_USERNAME") and os.getenv("KAGGLE_KEY"))


def ensure_kaggle_file(dataset_slug: str, filename: str) -> str:
    if not KAGGLE_AVAILABLE:
        raise RuntimeError("Kaggle ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
    if not kaggle_authenticate_if_possible():
        raise RuntimeError("Kaggle ì¸ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤. Kaggle íƒ­ì—ì„œ kaggle.jsonì„ ì—…ë¡œë“œí•˜ê±°ë‚˜ í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
    dl_dir = os.path.join(os.getcwd(), "kaggle_data")
    os.makedirs(dl_dir, exist_ok=True)
    target_path = os.path.join(dl_dir, filename)
    if not os.path.exists(target_path):
        kaggle_api.dataset_download_file(dataset=dataset_slug, file_name=filename, path=dl_dir, force=False, quiet=True)  # type: ignore[union-attr]
        # download_file leaves as .csv or .zip? For single file, it downloads exact file; if zipped, handle
        if not os.path.exists(target_path):
            # Try full dataset download & unzip as fallback
            kaggle_api.dataset_download_files(dataset_slug, path=dl_dir, unzip=True, quiet=True)  # type: ignore[union-attr]
    if not os.path.exists(target_path):
        # After unzip, search for the file
        for f in os.listdir(dl_dir):
            if f.lower() == filename.lower():
                target_path = os.path.join(dl_dir, f)
                break
    if not os.path.exists(target_path):
        raise RuntimeError(f"Kaggle íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {dataset_slug} / {filename}")
    return target_path


# -----------------------------
# ê³µê°œ ë°ì´í„° ë¡œë”
# -----------------------------
@st.cache_data(ttl=60 * 60)
def load_owid_co2_emissions_world() -> pd.DataFrame:
    # OWID ì „ì„¸ê³„ COâ‚‚ ë°°ì¶œëŸ‰ (Mt) ì—°ë„ë³„
    if LOCAL_CO2_WORLD.exists():
        try:
            df_local = pd.read_csv(LOCAL_CO2_WORLD, parse_dates=["date"])
            out_local = df_local.dropna(subset=["date", "value"]).sort_values("date").reset_index(drop=True)
            if len(out_local):
                return drop_future(out_local, "date")
        except Exception:
            pass
    url = "https://raw.githubusercontent.com/owid/co2-data/master/owid-co2-data.csv"
    resp = robust_get(url)
    df = pd.read_csv(io.StringIO(resp.text))
    df = df[df["country"] == "World"]
    slim = df[["year", "co2"]].rename(columns={"year": "year", "co2": "value"}).dropna()
    slim["date"] = pd.to_datetime(slim["year"].astype(int).astype(str) + "-12-31")
    out = slim[["date", "value", "year"]].sort_values("date")
    out = drop_future(out, "date").reset_index(drop=True)
    try:
        DATA_DIR.mkdir(exist_ok=True)
        out.to_csv(LOCAL_CO2_WORLD, index=False)
    except Exception:
        pass
    return out.dropna(subset=["value"]).drop_duplicates(subset=["date"])


@st.cache_data(ttl=60 * 60)
def load_noaa_mlo_co2_monthly() -> pd.DataFrame:
    # NOAA Mauna Loa COâ‚‚ ì›”ë³„ ë†ë„
    url = "https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_mm_mlo.csv"
    resp = robust_get(url)
    df = pd.read_csv(io.StringIO(resp.text), comment="#")
    cols_lower = {str(c).lower().strip(): c for c in df.columns}
    year_col = cols_lower.get("year")
    month_col = cols_lower.get("month")
    trend_col = cols_lower.get("trend") or cols_lower.get("average")
    if not (year_col and month_col and trend_col):
        raise RuntimeError("ì˜ˆìƒ ì»¬ëŸ¼(year, month, trend/average) ì—†ìŒ")
    df["date"] = pd.to_datetime(
        df[year_col].astype(int).astype(str)
        + "-"
        + df[month_col].astype(int).astype(str).str.zfill(2)
        + "-15"
    )
    df["value"] = pd.to_numeric(df[trend_col], errors="coerce")
    out = df.dropna(subset=["value"])[["date", "value"]].sort_values("date")
    out = drop_future(out, "date").reset_index(drop=True)
    return out.dropna().drop_duplicates()


def _read_gistemp_csv(csv_path: Path) -> pd.DataFrame:
    df = pd.read_csv(csv_path, parse_dates=["date"])
    if not {"date", "value"}.issubset(df.columns):
        raise RuntimeError("GISTEMP CSV í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    df["value"] = pd.to_numeric(df["value"], errors="coerce")
    out = df.dropna(subset=["date", "value"]).sort_values("date").reset_index(drop=True)
    return drop_future(out, "date")


@st.cache_data(ttl=60 * 60)
def load_nasa_gistemp_monthly_global() -> pd.DataFrame:
    # NASA GISTEMP v4 ì „ì§€êµ¬ ì›”ë³„ ê¸°ì˜¨ ì´ìƒ(Â°C)
    if LOCAL_GISTEMP_MONTHLY.exists():
        try:
            return _read_gistemp_csv(LOCAL_GISTEMP_MONTHLY)
        except Exception:
            pass
    url = "https://data.giss.nasa.gov/gistemp/tabledata_v4/GLB.Ts+dSST.csv"
    resp = robust_get(url)
    raw = pd.read_csv(io.StringIO(resp.text), skiprows=1)
    month_cols = [m for m in ["Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"] if m in raw.columns]
    if not month_cols or "Year" not in raw.columns:
        raise RuntimeError("NASA GISTEMP ìŠ¤í‚¤ë§ˆ ë³€ë™")
    df = raw[["Year"] + month_cols].copy()
    df = df.melt(id_vars="Year", value_vars=month_cols, var_name="month", value_name="anomaly")
    df["anomaly"] = pd.to_numeric(df["anomaly"], errors="coerce")
    scale = 0.01 if df["anomaly"].abs().mean(skipna=True) > 10 else 1.0
    df["anomaly"] = df["anomaly"] * scale
    month_map = dict(zip(month_cols, range(1, len(month_cols) + 1)))
    df["month_num"] = df["month"].map(month_map)
    df["date"] = pd.to_datetime(df["Year"].astype(int).astype(str) + "-" + df["month_num"].astype(int).astype(str) + "-15")
    out = df.dropna(subset=["anomaly"])[["date", "anomaly"]].rename(columns={"anomaly": "value"}).sort_values("date")
    out = drop_future(out, "date").reset_index(drop=True)
    try:
        DATA_DIR.mkdir(exist_ok=True)
        out.to_csv(LOCAL_GISTEMP_MONTHLY, index=False)
    except Exception:
        pass
    return out.dropna().drop_duplicates()


APP_ROOT = Path(__file__).resolve().parent
DATA_DIR = APP_ROOT / "data"
LOCAL_COUNTRY_TEMP = DATA_DIR / "country_temperature_annual.csv"
LOCAL_PISA_SCORES = DATA_DIR / "pisa_scores_2006_2018.csv"
LOCAL_GISTEMP_MONTHLY = DATA_DIR / "nasa_gistemp_global_monthly.csv"
LOCAL_CO2_WORLD = DATA_DIR / "owid_world_co2_annual.csv"


def _read_country_temperature_csv(csv_path: Path) -> pd.DataFrame:
    df = pd.read_csv(csv_path)
    required_cols = {"entity", "year", "date", "value"}
    missing = required_cols.difference(df.columns)
    if missing:
        raise RuntimeError(f"í•„ìˆ˜ ì—´ ëˆ„ë½: {', '.join(sorted(missing))}")
    df["date"] = pd.to_datetime(df["date"], errors="coerce")
    df = df.dropna(subset=["date", "value", "entity", "year"]).copy()
    df["year"] = df["year"].astype(int)
    return df.sort_values(["entity", "year"]).reset_index(drop=True)


@st.cache_data(ttl=60 * 60)
def load_pisa_scores() -> pd.DataFrame:
    df = pd.read_csv(LOCAL_PISA_SCORES)
    required_cols = {"entity", "year", "subject", "score"}
    missing = required_cols.difference(df.columns)
    if missing:
        raise RuntimeError(f"í•„ìˆ˜ ì—´ ëˆ„ë½: {', '.join(sorted(missing))}")
    df["year"] = pd.to_numeric(df["year"], errors="coerce").astype("Int64")
    df["score"] = pd.to_numeric(df["score"], errors="coerce")
    df = df.dropna(subset=["entity", "year", "score"]).copy()
    return df.sort_values(["entity", "year", "subject"]).reset_index(drop=True)


@st.cache_data(ttl=60 * 60)
def load_country_temperature_change() -> pd.DataFrame:
    """Berkeley Earth êµ­ê°€ë³„ í‰ê· ê¸°ì˜¨(ì—°ë„ë³„) ì‹¤ì œ ë°ì´í„° ë¡œë“œ"""
    if LOCAL_COUNTRY_TEMP.exists():
        return _read_country_temperature_csv(LOCAL_COUNTRY_TEMP)

    dataset = "berkeleyearth/climate-change-earth-surface-temperature-data"
    filename = "GlobalLandTemperaturesByCountry.csv"
    path = ensure_kaggle_file(dataset, filename)
    raw = pd.read_csv(path)
    need = [c for c in ["dt", "AverageTemperature", "Country"] if c in raw.columns]
    if len(need) < 3:
        raise RuntimeError("í•„ìˆ˜ ì—´(dt, AverageTemperature, Country)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    df = raw[need].rename(columns={"dt": "date", "AverageTemperature": "temp", "Country": "entity"})
    df["date"] = pd.to_datetime(df["date"], errors="coerce")
    df = df.dropna(subset=["date", "temp", "entity"]).copy()
    df["year"] = df["date"].dt.year
    ann = (
        df.groupby(["entity", "year"], as_index=False)
        .agg(value=("temp", "mean"))
    )
    ann["date"] = pd.to_datetime(ann["year"].astype(int).astype(str) + "-12-31")
    ann = ann[["entity", "year", "date", "value"]].sort_values(["entity", "year"]).reset_index(drop=True)

    try:
        DATA_DIR.mkdir(exist_ok=True)
        ann.to_csv(LOCAL_COUNTRY_TEMP, index=False)
    except Exception:
        pass

    return ann


# -----------------------------
# ì˜ˆì‹œ ë°ì´í„°(ê³µê°œ API ì‹¤íŒ¨ ì‹œ ëŒ€ì²´)
# -----------------------------
def sample_world_emissions() -> pd.DataFrame:
    years = [2015, 2018, 2021, 2024]
    vals = [35000, 36500, 37000, 37500]
    return pd.DataFrame({"date": pd.to_datetime([f"{y}-12-31" for y in years]), "value": vals})


def sample_noaa_co2() -> pd.DataFrame:
    d = pd.date_range("2022-01-15", periods=12, freq="MS") + pd.Timedelta(days=14)
    v = np.linspace(415, 422, len(d))
    return pd.DataFrame({"date": d, "value": v})


def sample_gistemp() -> pd.DataFrame:
    d = pd.date_range("2021-01-15", periods=24, freq="MS") + pd.Timedelta(days=14)
    v = 0.6 + 0.2 * np.sin(np.linspace(0, 4 * np.pi, len(d)))
    return pd.DataFrame({"date": d, "value": v})


def sample_country_temp_change() -> pd.DataFrame:
    data = [
        {"code": "KOR", "entity": "Korea, Republic of", "year": 2010, "value": 0.8},
        {"code": "KOR", "entity": "Korea, Republic of", "year": 2020, "value": 1.2},
        {"code": "USA", "entity": "United States", "year": 2010, "value": 0.9},
        {"code": "USA", "entity": "United States", "year": 2020, "value": 1.3},
        {"code": "JPN", "entity": "Japan", "year": 2010, "value": 0.7},
        {"code": "JPN", "entity": "Japan", "year": 2020, "value": 1.1},
    ]
    df = pd.DataFrame(data)
    df["date"] = pd.to_datetime(df["year"].astype(str) + "-12-31")
    return df[["code", "entity", "date", "value", "year"]]


# -----------------------------
# ì‹œê°í™” ìœ í‹¸
# -----------------------------
def line_chart(df: pd.DataFrame, title: str, y_title: str, smooth: int = 0) -> go.Figure:
    data = df.copy().sort_values("date").dropna()
    ycol = "value"
    if smooth and smooth > 1:
        data["value_smooth"] = data["value"].rolling(smooth, min_periods=1, center=True).mean()
        ycol = "value_smooth"
    fig = px.line(data, x="date", y=ycol, title=title)
    fig.update_layout(xaxis_title="ë‚ ì§œ", yaxis_title=y_title)
    return fig


def choropleth_by_year(df: pd.DataFrame, year: int, title: str) -> go.Figure:
    snap = df[df["date"].dt.year == year]
    fig = px.choropleth(
        snap,
        locations="entity",
        locationmode="country names",
        color="value",
        hover_name="entity",
        color_continuous_scale="RdYlBu_r",
        title=title,
    )
    fig.update_layout(coloraxis_colorbar=dict(title="í‰ê· ê¸°ì˜¨(Â°C)"))
    return fig


def download_button_for_df(df: pd.DataFrame, label: str, file_name: str):
    csv = df.to_csv(index=False).encode("utf-8")
    st.download_button(label=label, data=csv, file_name=file_name, mime="text/csv")


# -----------------------------
# ì‚¬ìš©ì ì„¤ëª… ê¸°ë°˜ ë°ì´í„°
# -----------------------------
DESCRIPTION_TEXT = """
ì„œë¡  (ë¬¸ì œ ì œê¸°)
ê¸°í›„ ë³€í™”ê°€ ê³„ì† ë¨ì— ë”°ë¼ í•™ìƒë“¤ì´ ê¸°ì˜¨ ë³€í™”ë¡œ ì¸í•´ í‰ì†Œ ë³´ë‹¤ ë” í° ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ ë°›ëŠ” ê²ƒì„ ëŠê¼ˆë‹¤. ì ì  ë†’ì•„ì§€ëŠ” ìµœê³ ê¸°ì˜¨ê³¼ ê¸¸ì–´ì§€ëŠ” ë”ìœ„ê°€ í•™ìƒë“¤ì˜ í•™ì—… ì„±ì ì— ì „í˜€ ë¬´ê´€í• ê¹Œ? í•˜ëŠ” ê¶ê¸ˆì¦ì„ ê°€ì§„ ìš°ë¦¬ëŠ” í•™ìƒë“¤ì˜ í•™ì—…ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì— ê´€í•œ ê¶ê¸ˆì¦ì„ í•´ì†Œí•˜ê³ , ì´ë¥¼ í•™ìƒë“¤ì—ê²Œ ì•Œë ¤ ê¸°ì˜¨ ìƒìŠ¹ ìƒí™©ì—ì„œ ì„±ì  ìƒìŠ¹ì„ ë•ê¸°ìœ„í•´ì„œ ì´ ì£¼ì œë¥¼ ì„ ì •í•´ ì—°êµ¬í•œë‹¤.

ì¸ë¥˜ í™œë™ìœ¼ë¡œ ë°œìƒí•œ ì§€êµ¬ ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œëŸ‰ì€ ì ì  ì¦ê°€í•˜ê³  ëŒ€ê¸° ì¤‘ ì´ì‚°í™”íƒ„ì†Œ ë†ë„ê°€  ë†’ì•„ì§€ë©° ì „ì§€êµ¬ í‰ê· ê¸°ì˜¨ë„ ë†’ì•„ì§€ê³  ìˆë‹¤. í™”ì„ ì—°ë£Œ ì‚¬ìš© ì¦ê°€ ë° ì‚°ì—… ë°œì „ê³¼ ì¸êµ¬ ì¦ê°€ë¡œ ì¸í•´ ê³¼ë„í•œ ì—ë„ˆì§€ ì†Œë¹„ê°€ ì¼ì–´ë‚˜ëŠ” ê²ƒì´ ì£¼ëœ ì›ì¸ì´ë‹¤.

ë³¸ë¡  1 (ë°ì´í„° ë¶„ì„)
ì´ë²ˆ ì—°êµ¬ì—ì„œëŠ” ê¸°í›„ ë³€í™”ì™€ ìˆ˜ë©´ ì‹œê°„ì˜ ê´€ê³„ë¥¼ ë¶„ì„í•˜ì˜€ë‹¤. ìµœê·¼ ê¸°ì˜¨ ìƒìŠ¹ì€ ë‹¨ìˆœí•œ ìƒí™œ ë¶ˆí¸ì´ ì•„ë‹Œ ì²­ì†Œë…„ë“¤ì˜ ìˆ˜ë©´ íŒ¨í„´ì—ë„ í° ì˜í–¥ì„ ì£¼ê³  ìˆë‹¤. ì„  ê·¸ë˜í”„ë¥¼ í†µí•´ ë¶„ì„ í•œ ê²°ê³¼, ê¸°ì˜¨ì´ ë†’ì•„ì§ˆìˆ˜ë¡ í‰ê·  ìˆ˜ë©´ì‹œê°„ì´ ì ì°¨ ì¤„ì–´ë“œëŠ” ê²½í–¥ì´ í™•ì¸ë˜ì—ˆë‹¤.
íŠ¹íˆ ë”ìš´ ë‚ ì”¨ì—ëŠ” í•™ìƒë“¤ì´ ê¹Šì€ ì ì— ë“œëŠ” ì‹œê°„ì´ ì§§ì•„ì§€ê³ , ìì£¼ ê¹¨ëŠ” ê²½ìš°ê°€ ë§ì•„ ìˆ˜ë©´ì˜ ì§ˆ ë˜í•œ ë–¨ì–´ì§€ëŠ” ëª¨ìŠµì„ ë³´ì˜€ë‹¤. ì´ëŠ” ê³§ ìˆ˜ë©´ ë¶€ì¡±ìœ¼ë¡œ ì´ì–´ì§€ë©°, í•™ìŠµ íš¨ìœ¨ ì €í•˜ì™€ ì§‘ì¤‘ë ¥ ê°ì†Œì˜ ì›ì¸ìœ¼ë¡œ ì‘ìš©í•  ìˆ˜ ìˆë‹¤.
ë”°ë¼ì„œ ê¸°í›„ ë³€í™”ëŠ” ë‹¨ìˆœíˆ í™˜ê²½ì  ìœ„ê¸°ë§Œì´ ì•„ë‹ˆë¼, ì²­ì†Œë…„ë“¤ì˜ ìˆ˜ë©´ê³¼ í•™ìŠµ ëŠ¥ë ¥ì— ì˜í–¥ì„ ì£¼ëŠ” ì¤‘ìš”í•œ ìš”ì¸ì„ì„ ì•Œ ìˆ˜ ìˆë‹¤.

ë³¸ë¡  2 (ì›ì¸ ë° ì˜í–¥ íƒêµ¬)
ê¸°ì˜¨ ë³€í™”ì™€ ì„±ì ì€ ì‹¤ì œë¡œ ìƒê´€ê´€ê³„ë¥¼ ê°€ì§„ë‹¤.
ì•„ë˜ì˜ ë§‰ëŒ€ ê·¸ë˜í”„ì™€ ì‚°ì ë„ë¥¼ ì‚´í”¼ë©´ ë” ì •í™•íˆ ì•Œ ìˆ˜ ìˆë‹¤.

ìœ„ì˜ ë§‰ëŒ€ê·¸ë˜í”„ëŠ” ì „ ì„¸ê³„ ë‹¤ì–‘í•œ ì—°êµ¬ì—ì„œ ë³´ê³ ëœ ê¸°ì˜¨ ìƒìŠ¹ê³¼ í•™ì—… ì„±ì  ë³€í™”ì˜ ìƒê´€ê´€ê³„ë¥¼ ë¹„êµí•œ ê²ƒì´ë‹¤. ê·¸ë˜í”„ì—ì„œ ë³¼ ìˆ˜ ìˆë“¯ì´, ëŒ€ë¶€ë¶„ì˜ ì—°êµ¬ì—ì„œ ê¸°ì˜¨ì´ ì¼ì • ìˆ˜ì¤€ ì´ìƒ ìƒìŠ¹í•˜ë©´ í•™ìƒë“¤ì˜ ì„±ì ì´ í‘œì¤€í¸ì°¨ ë‹¨ìœ„ë¡œ ê°ì†Œí•˜ëŠ” ê²½í–¥ì´ ë‚˜íƒ€ë‚œë‹¤.
íŠ¹íˆ OECD êµ­ì œí•™ì—…ì„±ì·¨ë„ í‰ê°€(PISA)ë¥¼ í™œìš©í•œ 58ê°œêµ­ ë¶„ì„ì—ì„œëŠ” ê³ ì˜¨ ë…¸ì¶œì´ ëˆ„ì ë ìˆ˜ë¡ ì„±ì ì´ í¬ê²Œ í•˜ë½í•˜ëŠ” ê²°ê³¼ê°€ í™•ì¸ë˜ì—ˆë‹¤. ë¯¸êµ­ê³¼ ë‰´ìš•ì˜ ì‚¬ë¡€ ë˜í•œ ì‹œí—˜ ë‹¹ì¼ ê¸°ì˜¨ì´ ë†’ì„ìˆ˜ë¡ í•™ìƒë“¤ì˜ ì„±ì ê³¼ í•©ê²©ë¥ ì´ ìœ ì˜í•˜ê²Œ ë–¨ì–´ì¡Œë‹¤. í•œêµ­ì˜ ê²½ìš° ë‹¨ì¼ ê³ ì˜¨ì¼ì˜ íš¨ê³¼ëŠ” ë¹„êµì  ì‘ì§€ë§Œ, 34â„ƒ ì´ìƒì˜ ë‚ ì´ ëˆ„ì ë ìˆ˜ë¡ ìˆ˜í•™ê³¼ ì˜ì–´ ì„±ì ì´ ì ì°¨ ê°ì†Œí•˜ëŠ” ê²½í–¥ì„ ë³´ì˜€ë‹¤.
ì´ì²˜ëŸ¼ ê³ ì˜¨ í™˜ê²½ì€ ë‹¨ìˆœí•œ ë¶ˆì¾Œê°ì„ ë„˜ì–´ í•™ì—… ì„±ì·¨ì—ë„ ë¶€ì •ì ì¸ ì˜í–¥ì„ ë¯¸ì¹˜ë©°, íŠ¹íˆ ëˆ„ì  íš¨ê³¼ê°€ ì¥ê¸°ì ì¸ ì„±ì  ì €í•˜ë¡œ ì´ì–´ì§ˆ ìˆ˜ ìˆìŒì„ ì‹œì‚¬í•œë‹¤.

ìœ„ ê·¸ë¦¼ì€ 2012ë…„ PISA(íŒ¨ë„ A) ë˜ëŠ” SEDA(íŒ¨ë„ B) ìˆ˜í•™ í‰ê·  ì ìˆ˜ì™€ êµ­ê°€ ë˜ëŠ” ë¯¸êµ­ ì¹´ìš´í‹°ë³„ ì—°í‰ê·  ê¸°ì˜¨ì˜ ì‚°ì ë„ì´ë‹¤.

ì—°í‰ê·  ê¸°ì˜¨ì€ 1980ë…„ë¶€í„° 2011ë…„ê¹Œì§€ ì¸¡ì •ë˜ì—ˆê³ , íŒ¨ë„ BëŠ” í‰ê·  ê¸°ì˜¨ ë¶„í¬ì˜ ë°±ë¶„ìœ„ ë³„ë¡œ í‘œì¤€í™”ëœ 3~8í•™ë…„ ìˆ˜í•™ ì ìˆ˜(2009~2013ë…„)ì˜ êµ¬ê°„ë³„ ë°±ë¶„ìœ„ ê·¸ë˜í”„ì´ë‹¤. ì ìˆ˜ëŠ” ê³¼ëª©, í•™ë…„, ì—°ë„ë³„ë¡œ í‘œì¤€í™”ëœ ì ìˆ˜ë¥¼ ì‚¬ìš©í•œë‹¤.

ì´ ì‚°ì ë„ëŠ” ê°„ë‹¨íˆ ë§í•˜ìë©´ ë¯¸êµ­ í•™ìƒë“¤ì˜ ìˆ˜í•™ ì„±ì ì´ ê¸°ì˜¨ì— ë”°ë¼ ì–´ë–»ê²Œ ë³€í™”í•˜ëŠ”ì§€ ë³´ì—¬ì¤€ë‹¤. ìœ„ ê·¸ë˜í”„ëŠ” ê¸°ì˜¨ì´ ë†’ì•„ì§ˆ ìˆ˜ë¡ ì„±ì ì´ í•˜ë½í•˜ëŠ” ê²½í–¥ì„ ë©´ë°€íˆ ë³´ì—¬ì£¼ê³  ìˆë‹¤. ë”°ë¼ì„œ ìš°ë¦¬ëŠ” ê¸°ì˜¨ ìƒìŠ¹ì´ í•™ìƒë“¤ì˜ ì„±ì ì— ë°€ì ‘í•œ ì—°ê´€ì„ ê°€ì§„ë‹¤ëŠ” ì‚¬ì‹¤ì„ ì•Œ ìˆ˜ ìˆë‹¤.

ê²°ë¡  (ì œì–¸)
ì´ë²ˆ ì—°êµ¬ë¥¼ í†µí•´ ìš°ë¦¬ëŠ” ê¸°ì˜¨ ìƒìŠ¹ì´ ë‹¨ìˆœíˆ ìƒí™œ ë¶ˆí¸ì— ê·¸ì¹˜ì§€ ì•Šê³ , í•™ìƒë“¤ì˜ ìˆ˜ë©´ ì§ˆ ì €í•˜ì™€ ì§‘ì¤‘ë ¥ ê°ì†Œë¥¼ ì´ˆë˜í•˜ë©°, í•™ì—… ì„±ì·¨ë„ì— ë¶€ì •ì ì¸ ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆìŒì„ í™•ì¸í•˜ì˜€ë‹¤. íŠ¹íˆ ê¸°ì˜¨ì´ ì¼ì • ìˆ˜ì¤€ ì´ìƒ ìƒìŠ¹í•  ê²½ìš° ì„±ì ì´ í‘œì¤€í¸ì°¨ ë‹¨ìœ„ë¡œ ê°ì†Œí•˜ëŠ” ê²½í–¥ì´ ì—¬ëŸ¬ ì—°êµ¬ì—ì„œ ê³µí†µì ìœ¼ë¡œ ë“œëŸ¬ë‚¬ë‹¤. ì´ëŠ” ë‹¨ì¼ ìš”ì¸ì´ ì•„ë‹Œ, ë°˜ë³µì ì´ê³  ëˆ„ì ëœ ë†’ì€ ì˜¨ë„ ë…¸ì¶œì´ ì¥ê¸°ì ìœ¼ë¡œ í•™ìƒë“¤ì˜ í•™ìŠµ ëŠ¥ë ¥ì„ ì €í•´í•œë‹¤ëŠ” ì ì„ ë³´ì—¬ì¤€ë‹¤.
"""


def build_description_based_dataset() -> tuple[pd.DataFrame, pd.DataFrame]:
    records = [
        {"ì—°êµ¬": "PISA 58ê°œêµ­", "ì§€í‘œ": "ì„±ì ", "ë°©í–¥": "í•˜ë½", "ê°•ë„": "ë†’ìŒ"},
        {"ì—°êµ¬": "ë¯¸êµ­(ì „êµ­)", "ì§€í‘œ": "ì„±ì ", "ë°©í–¥": "í•˜ë½", "ê°•ë„": "ë³´í†µ"},
        {"ì—°êµ¬": "ë‰´ìš•", "ì§€í‘œ": "ì„±ì ", "ë°©í–¥": "í•˜ë½", "ê°•ë„": "ë³´í†µ"},
        {"ì—°êµ¬": "í•œêµ­", "ì§€í‘œ": "ì„±ì ", "ë°©í–¥": "í•˜ë½", "ê°•ë„": "ë‚®ìŒ"},
        {"ì—°êµ¬": "ì „ë°˜", "ì§€í‘œ": "ìˆ˜ë©´ì‹œê°„", "ë°©í–¥": "ê°ì†Œ", "ê°•ë„": "ë³´í†µ"},
        {"ì—°êµ¬": "ì „ë°˜", "ì§€í‘œ": "ìˆ˜ë©´ì§ˆ", "ë°©í–¥": "ì €í•˜", "ê°•ë„": "ë³´í†µ"},
    ]
    df = pd.DataFrame(records)
    order = {"ë‚®ìŒ": 1, "ë³´í†µ": 2, "ë†’ìŒ": 3}
    df["ê°•ë„ì ìˆ˜"] = df["ê°•ë„"].map(order)
    df_std = df.copy()
    df_std["date"] = pd.NaT
    df_std["value"] = df_std["ê°•ë„ì ìˆ˜"]
    df_std["group"] = df_std["ì§€í‘œ"]
    return df, df_std[["date", "value", "group"]]


# -----------------------------
# ì•± ë³¸ë¬¸
# -----------------------------
st.title("ê¸°í›„ ë³€í™”ì™€ í•™ìŠµ ì˜í–¥ ëŒ€ì‹œë³´ë“œ")

st.markdown(
    """
- ì¸ë¥˜ í™œë™ì— ë”°ë¥¸ ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œ ì¦ê°€ â†’ ëŒ€ê¸° ì¤‘ COâ‚‚ ë†ë„ ìƒìŠ¹ â†’ ì „ì§€êµ¬ í‰ê· ê¸°ì˜¨ ìƒìŠ¹
- ê³µê°œ ë°ì´í„° ê¸°ë°˜ ì‹œê³„ì—´ê³¼, ì œê³µëœ ì„¤ëª… ê¸°ë°˜ ì •ì„± ì‹œê°í™”ë¥¼ í•¨ê»˜ ì œê³µí•©ë‹ˆë‹¤.
"""
)

# ì‚¬ì´ë“œë°”(ê³µí†µ ì˜µì…˜)
st.sidebar.header("ì˜µì…˜")
smooth_co2em = st.sidebar.number_input("ì—°ê°„ COâ‚‚ ë°°ì¶œëŸ‰: ìŠ¤ë¬´ë”©(ì´ë™í‰ê· )", min_value=0, max_value=60, value=0, step=1)
smooth_noaa = st.sidebar.number_input("Mauna Loa COâ‚‚: ìŠ¤ë¬´ë”©(ì´ë™í‰ê· )", min_value=0, max_value=24, value=6, step=1)
smooth_gis = st.sidebar.number_input("ê¸°ì˜¨ ì´ìƒ: ìŠ¤ë¬´ë”©(ì´ë™í‰ê· )", min_value=0, max_value=24, value=12, step=1)

# KPI ì˜ì—­
try:
    _em = load_owid_co2_emissions_world()
    em_last = _em.dropna().sort_values("date").iloc[-1]["value"] if len(_em) else None
except Exception:
    em_last = None
try:
    _co2 = load_noaa_mlo_co2_monthly()
    co2_last = _co2.dropna().sort_values("date").iloc[-1]["value"] if len(_co2) else None
except Exception:
    co2_last = None
try:
    _gt = load_nasa_gistemp_monthly_global()
    gt_last = _gt.dropna().sort_values("date").iloc[-1]["value"] if len(_gt) else None
except Exception:
    gt_last = None

col_a, col_b, col_c = st.columns(3)
col_a.metric("ì „ì„¸ê³„ COâ‚‚ ë°°ì¶œëŸ‰(ìµœê·¼, Mt)", f"{em_last:,.0f}" if em_last is not None else "-")
col_b.metric("ëŒ€ê¸° COâ‚‚(ìµœê·¼, ppm)", f"{co2_last:,.2f}" if co2_last is not None else "-")
col_c.metric("ì „ì§€êµ¬ ì´ìƒê¸°ì˜¨(ìµœê·¼, Â°C)", f"{gt_last:+.2f}" if gt_last is not None else "-")

st.markdown("---")

# íƒ­ êµ¬ì„±
extra_tabs = ["Kaggle"] if KAGGLE_AVAILABLE else []
tab1, tab2, tab3, tab4, *rest = st.tabs(["ì‹œê³„ì—´", "ì„¸ê³„ ì§€ë„", "ìƒê´€ê´€ê³„", "ì‚¬ìš©ì ì„¤ëª…", *extra_tabs])

with tab1:
    st.subheader("ì‹œê³„ì—´ ì§€í‘œ")
    c1, c2 = st.columns([1, 1])
    with c1:
        st.markdown("#### ì „ì„¸ê³„ COâ‚‚ ë°°ì¶œëŸ‰ (ì—°ê°„, Mt)")
        try:
            df_em = load_owid_co2_emissions_world()
        except Exception:
            st.warning("ê³µì‹ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨ â†’ ì˜ˆì‹œ ë°ì´í„°ë¡œ í‘œì‹œí•©ë‹ˆë‹¤.")
            df_em = sample_world_emissions()
        df_em = df_em.dropna().drop_duplicates()
        fig_em = line_chart(df_em, "ì „ì„¸ê³„ COâ‚‚ ë°°ì¶œëŸ‰", "ë°°ì¶œëŸ‰ (Mt)", smooth=smooth_co2em)
        st.plotly_chart(fig_em, use_container_width=True)
        download_button_for_df(df_em, "CSV ë‹¤ìš´ë¡œë“œ(ì „ì„¸ê³„ COâ‚‚ ë°°ì¶œëŸ‰)", "world_co2_emissions.csv")

    with c2:
        st.markdown("#### ëŒ€ê¸° ì¤‘ COâ‚‚ (ì›”ë³„, ppm)")
        try:
            df_co2 = load_noaa_mlo_co2_monthly()
        except Exception:
            st.warning("NOAA COâ‚‚ ë¡œë“œ ì‹¤íŒ¨ â†’ ì˜ˆì‹œ ë°ì´í„°ë¡œ í‘œì‹œí•©ë‹ˆë‹¤.")
            df_co2 = sample_noaa_co2()
        df_co2 = df_co2.dropna().drop_duplicates()
        fig_co2 = line_chart(df_co2, "Mauna Loa ëŒ€ê¸° COâ‚‚", "ë†ë„ (ppm)", smooth=smooth_noaa)
        st.plotly_chart(fig_co2, use_container_width=True)
        download_button_for_df(df_co2, "CSV ë‹¤ìš´ë¡œë“œ(ëŒ€ê¸° COâ‚‚)", "noaa_co2_monthly.csv")

    st.markdown("#### ì „ì§€êµ¬ í‰ê· ê¸°ì˜¨ ì´ìƒ(ì›”ë³„, Â°C)")
    try:
        df_temp = load_nasa_gistemp_monthly_global()
    except Exception:
        st.warning("NASA GISTEMP ë¡œë“œ ì‹¤íŒ¨ â†’ ì˜ˆì‹œ ë°ì´í„°ë¡œ í‘œì‹œí•©ë‹ˆë‹¤.")
        df_temp = sample_gistemp()
    df_temp = df_temp.dropna().drop_duplicates()
    fig_temp = line_chart(df_temp, "ì „ì§€êµ¬ í‰ê· ê¸°ì˜¨ ì´ìƒ(ì›”ë³„)", "ì´ìƒê¸°ì˜¨ (Â°C)", smooth=smooth_gis)
    st.plotly_chart(fig_temp, use_container_width=True)
    download_button_for_df(df_temp, "CSV ë‹¤ìš´ë¡œë“œ(ì „ì§€êµ¬ ì´ìƒê¸°ì˜¨)", "nasa_gistemp_global_monthly.csv")

with tab2:
    st.subheader("êµ­ê°€ë³„ í‰ê· ê¸°ì˜¨ ì„¸ê³„ ì§€ë„(ì—°ë„ë³„)")
    try:
        df_country = load_country_temperature_change()
    except Exception as e:
        st.error(f"êµ­ê°€ë³„ ì˜¨ë„ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        df_country = None
    if df_country is not None and len(df_country):
        df_country = df_country.copy()
        df_country["date"] = pd.to_datetime(df_country["date"])  # í‘œì¤€í™”
        years = sorted(df_country["date"].dt.year.unique().tolist())
        if years:
            sel_year = st.slider("ì—°ë„ ì„ íƒ", min_value=int(min(years)), max_value=int(max(years)), value=int(max(years)), step=1)
            fig_map = choropleth_by_year(df_country, sel_year, f"êµ­ê°€ë³„ í‰ê· ê¸°ì˜¨(Â°C) - {sel_year}")
            st.plotly_chart(fig_map, use_container_width=True)
            dl_df = df_country.rename(columns={"entity": "group"})[["date", "value", "group"]].sort_values(["date", "group"])
            download_button_for_df(dl_df, "CSV ë‹¤ìš´ë¡œë“œ(êµ­ê°€ë³„ í‰ê· ê¸°ì˜¨)", "country_avg_temperature_annual.csv")
        else:
            st.info("í‘œì‹œí•  ì—°ë„ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.caption("ì°¸ê³ : ì¼ë¶€ êµ­ê°€/ì—°ë„ëŠ” ê°’ì´ ì—†ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    else:
        st.info("ì‹¤ì œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ Kaggle ì¸ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤. Kaggle íƒ­ì—ì„œ kaggle.json ì—…ë¡œë“œ ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”. Docker ì‹¤í–‰ì„ ê¶Œì¥í•©ë‹ˆë‹¤.")

with tab3:
    st.subheader("ê¸°ì˜¨ê³¼ í•™ì—… ì„±ì·¨ ìƒê´€ê´€ê³„ (ì‹¤ì œ ë°ì´í„°)")
    st.markdown("""
    1) Kaggle íƒ­ì—ì„œ í•™ì—… ì„±ì·¨(ì˜ˆ: PISA) ê´€ë ¨ CSVë¥¼ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”.
    2) ì•„ë˜ì—ì„œ CSV íŒŒì¼ì„ ì„ íƒí•˜ê³ , êµ­ê°€/ì—°ë„/ì„±ì·¨ë„(ìˆ«ì) ì—´ì„ ì§€ì •í•©ë‹ˆë‹¤.
    3) ë™ì¼ ì—°ë„ì˜ êµ­ê°€ë³„ í‰ê· ê¸°ì˜¨(ë² ë¥¼ë¦¬ ì§€êµ¬ Kaggle ë°ì´í„°)ê³¼ ë³‘í•©í•˜ì—¬ ì‚°ì ë„ ë° ìƒê´€ê³„ìˆ˜ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.
    """)
    # ì˜¨ë„ ë°ì´í„° ì¤€ë¹„
    try:
        df_temp_c = load_country_temperature_change()
    except Exception as e:
        # Kaggle ë¯¸ì„¤ì¹˜ ì‹œì—ëŠ” ëª…í™•í•œ ì—ëŸ¬ ë¬¸êµ¬ë¡œ ì•ˆë‚´
        if not KAGGLE_AVAILABLE:
            st.error("êµ­ê°€ë³„ ì˜¨ë„ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: Kaggle ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
        else:
            st.error(f"ì˜¨ë„ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            st.info("Kaggle ì¸ì¦ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Kaggle íƒ­ì—ì„œ kaggle.json ì—…ë¡œë“œ ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
        df_temp_c = None

    if df_temp_c is not None and len(df_temp_c):
        dl_dir = os.path.join(os.getcwd(), "kaggle_data")
        csv_files = [f for f in os.listdir(dl_dir)] if os.path.isdir(dl_dir) else []
        csv_files = [f for f in csv_files if f.lower().endswith(".csv")]
        up_alt = st.file_uploader("(ëŒ€ì•ˆ) êµìœ¡ ì„±ì·¨ CSV ì§ì ‘ ì—…ë¡œë“œ", type=["csv"], accept_multiple_files=False)
        df_edu_raw: Optional[pd.DataFrame] = None

        built_in_sources: dict[str, pd.DataFrame] = {}
        if LOCAL_PISA_SCORES.exists():
            try:
                built_in_sources["ğŸ”¹ ë‚´ì¥: PISA 2006-2018 (OECD, CC0)"] = load_pisa_scores()
            except Exception as e:
                st.warning(f"ë‚´ì¥ PISA ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")

        available_sources: list[str] = []
        available_sources.extend(built_in_sources.keys())
        available_sources.extend(csv_files)

        if not available_sources and up_alt is None:
            st.info("í•™ì—… ì„±ì·¨ CSVê°€ ì—†ìŠµë‹ˆë‹¤. Kaggle íƒ­ì—ì„œ ë‹¤ìš´ë¡œë“œí•˜ê±°ë‚˜ ìœ„ì— íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
        else:
            if up_alt is not None:
                try:
                    df_edu_raw = pd.read_csv(up_alt)
                    st.success("ì—…ë¡œë“œí•œ CSVë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                except Exception as e:
                    st.error(f"ì—…ë¡œë“œ CSV ì½ê¸° ì‹¤íŒ¨: {e}")
            else:
                sel_label = st.selectbox("í•™ì—… ì„±ì·¨ ë°ì´í„° ì†ŒìŠ¤ ì„ íƒ", available_sources)
                if sel_label in built_in_sources:
                    df_source = built_in_sources[sel_label]
                    subjects = sorted(df_source["subject"].dropna().unique().tolist())
                    if subjects:
                        sel_subject = st.selectbox("ê³¼ëª© ì„ íƒ", subjects, key="pisa_subject")
                        df_source = df_source[df_source["subject"] == sel_subject].drop(columns=["subject"]).copy()
                        st.caption(f"ì„ íƒí•œ ê³¼ëª©: {sel_subject}")
                    df_edu_raw = df_source.rename(columns={"entity": "country"})
                else:
                    edu_path = os.path.join(dl_dir, sel_label)
                    try:
                        df_edu_raw = pd.read_csv(edu_path)
                    except Exception as e:
                        st.error(f"CSV ì½ê¸° ì‹¤íŒ¨: {e}")
                        df_edu_raw = None

        if df_edu_raw is not None:
            cols = df_edu_raw.columns.tolist()
            col_country = st.selectbox("êµ­ê°€ ì—´", cols)
            col_year = st.selectbox("ì—°ë„ ì—´", cols)
            col_score = st.selectbox("ì„±ì·¨ë„(ìˆ«ì) ì—´", cols)

            # ì „ì²˜ë¦¬
            edu = df_edu_raw[[col_country, col_year, col_score]].copy()
            edu.columns = ["entity", "year", "score"]
            # ì—°ë„ ìˆ«ìí™”
            edu["year"] = pd.to_numeric(edu["year"], errors="coerce").astype("Int64")
            # ì ìˆ˜ ìˆ«ìí™”
            edu["score"] = pd.to_numeric(edu["score"], errors="coerce")
            edu = edu.dropna(subset=["entity", "year", "score"]).copy()

            temp_for_merge = df_temp_c[["entity", "year", "value"]].copy()
            temp_for_merge["entity"] = temp_for_merge["entity"].astype(str)
            temp_for_merge["year"] = pd.to_numeric(temp_for_merge["year"], errors="coerce").astype("Int64")

            edu["entity"] = edu["entity"].astype(str)
            edu["year"] = pd.to_numeric(edu["year"], errors="coerce").astype("Int64")
            edu = edu.dropna(subset=["entity", "year", "score"]).copy()

            merged_all = pd.merge(
                temp_for_merge,
                edu,
                on=["entity", "year"],
                how="inner",
            ).rename(columns={"value": "temp"})

            if len(merged_all):
                countries = sorted(merged_all["entity"].unique().tolist())
                default_country = "South Korea" if "South Korea" in countries else countries[:1]
                default_selection = [default_country] if isinstance(default_country, str) else default_country
                sel_countries = st.multiselect(
                    "êº¾ì€ì„  ê·¸ë˜í”„ì— í‘œì‹œí•  êµ­ê°€ (ê¸°ë³¸: ëŒ€í•œë¯¼êµ­)",
                    countries,
                    default=default_selection,
                    key="line_countries",
                )
                line_df = merged_all[merged_all["entity"].isin(sel_countries)].sort_values(["entity", "year"])
                if len(line_df) >= 2 and sel_countries:
                    fig_line = go.Figure()
                    palette = px.colors.qualitative.Set2
                    for idx, country in enumerate(sel_countries):
                        country_df = line_df[line_df["entity"] == country]
                        if len(country_df) < 2:
                            continue
                        color_temp = palette[(2 * idx) % len(palette)]
                        color_score = palette[(2 * idx + 1) % len(palette)]
                        fig_line.add_trace(
                            go.Scatter(
                                x=country_df["year"],
                                y=country_df["temp"],
                                name=f"{country} ê¸°ì˜¨",
                                mode="lines+markers",
                                line=dict(color=color_temp),
                            )
                        )
                        fig_line.add_trace(
                            go.Scatter(
                                x=country_df["year"],
                                y=country_df["score"],
                                name=f"{country} ì„±ì·¨", 
                                mode="lines+markers",
                                yaxis="y2",
                                line=dict(color=color_score, dash="dash"),
                            )
                        )
                    fig_line.update_layout(
                        title="ì—°ë„ë³„ ê¸°ì˜¨Â·í•™ì—… ì„±ì·¨ êº¾ì€ì„  ì¶”ì´",
                        xaxis_title="ì—°ë„",
                        yaxis=dict(title="í‰ê· ê¸°ì˜¨(Â°C)", side="left"),
                        yaxis2=dict(
                            title="í•™ì—… ì„±ì·¨ ì ìˆ˜",
                            overlaying="y",
                            side="right",
                        ),
                        legend=dict(orientation="h", y=-0.2),
                    )
                    st.plotly_chart(fig_line, use_container_width=True)
                else:
                    st.info("ì„ íƒí•œ êµ­ê°€ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë‹¤ë¥¸ êµ­ê°€ë¥¼ ì¶”ê°€í•˜ê±°ë‚˜ ê¸°ê°„ì„ í™•ì¸í•˜ì„¸ìš”.")

            # ì—°ë„ ë²”ìœ„ ì„ íƒ
            if df_temp_c is not None and len(df_temp_c) and len(edu):
                y_min = int(max(edu["year"].min(), df_temp_c["year"].min()))
                y_max = int(min(edu["year"].max(), df_temp_c["year"].max()))
            else:
                y_min, y_max = 2000, 2018
            if y_min > y_max:
                y_min, y_max = y_max, y_max
            year_sel = st.slider("ì—°ë„ ì„ íƒ(ìƒê´€ê³„ìˆ˜ ê³„ì‚° ì—°ë„)", min_value=y_min, max_value=y_max, value=y_max, step=1)

            if df_temp_c is None:
                st.warning("ì˜¨ë„ ë°ì´í„°ê°€ ì—†ì–´ ìƒê´€ê´€ê³„ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Kaggle ì¸ì¦ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
            else:
                # ë™ì¼ ì—°ë„ ë³‘í•©(êµ­ê°€ëª… ê¸°ì¤€)
                temp_y = df_temp_c[df_temp_c["year"] == year_sel][["entity", "value"]].rename(columns={"value": "temp"})
                edu_y = edu[edu["year"] == year_sel][["entity", "score"]]
                merged = pd.merge(temp_y, edu_y, on="entity", how="inner")
                st.write(f"ë³‘í•©ëœ êµ­ê°€ ìˆ˜: {len(merged)}")
                if len(merged) < 5:
                    st.warning("ì¶©ë¶„í•œ êµ­ê°€ ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì—°ë„ë¥¼ ì„ íƒí•˜ê±°ë‚˜ ë§¤í•‘ì„ ì¡°ì •í•´ ë³´ì„¸ìš”.")
                else:
                    # í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜
                    try:
                        r = float(np.corrcoef(merged["temp"], merged["score"])[0, 1])
                    except Exception:
                        r = float("nan")
                    st.metric("í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜ r", f"{r:.3f}" if pd.notna(r) else "NaN")
                    # ì‚°ì ë„ + ë‹¨ìˆœ ì„ í˜•íšŒê·€ì„ 
                    fig_sc = px.scatter(merged, x="temp", y="score", hover_name="entity", title=f"{year_sel}ë…„: í‰ê· ê¸°ì˜¨(Â°C) vs í•™ì—… ì„±ì·¨")
                    # íšŒê·€ì„  ìˆ˜ë™ ì¶”ê°€
                    try:
                        m, b = np.polyfit(merged["temp"].astype(float), merged["score"].astype(float), 1)
                        xfit = np.linspace(float(merged["temp"].min()), float(merged["temp"].max()), 50)
                        yfit = m * xfit + b
                        fig_sc.add_trace(go.Scatter(x=xfit, y=yfit, mode="lines", name="íšŒê·€ì„ "))
                    except Exception:
                        pass
                    fig_sc.update_layout(xaxis_title="í‰ê· ê¸°ì˜¨(Â°C)", yaxis_title="í•™ì—… ì„±ì·¨(ì ìˆ˜)")
                    st.plotly_chart(fig_sc, use_container_width=True)


with tab4:
    st.subheader("ì‚¬ìš©ì ì…ë ¥ ëŒ€ì‹œë³´ë“œ (ì‹¤ì œ ë°ì´í„°)")
    st.caption("ëŒ€í•œë¯¼êµ­ì„ ê¸°ë³¸ìœ¼ë¡œ ì„ íƒí•˜ê³ , í•„ìš”í•˜ë©´ êµ­ê°€ì™€ ê¸°ê°„ì„ ì¶”ê°€í•´ ì‹¤ì¸¡ ë°ì´í„°ë¥¼ êº¾ì€ì„ ìœ¼ë¡œ ë¹„êµí•˜ì„¸ìš”.")

    try:
        temp_all = load_country_temperature_change()
        pisa_all = load_pisa_scores()
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        temp_all, pisa_all = None, None

    if temp_all is None or pisa_all is None or temp_all.empty or pisa_all.empty:
        st.warning("ê¸°ë³¸ ë°ì´í„°ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•„ ëŒ€ì‹œë³´ë“œë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        subjects = sorted(pisa_all["subject"].dropna().unique().tolist())
        default_subject_index = subjects.index("Maths") if "Maths" in subjects else 0
        sel_subject = st.selectbox("PISA ê³¼ëª© ì„ íƒ", subjects, index=default_subject_index)

        pisa_filtered = (
            pisa_all[pisa_all["subject"] == sel_subject][["entity", "year", "score"]]
            .rename(columns={"score": "pisa_score"})
            .copy()
        )
        pisa_filtered["entity"] = pisa_filtered["entity"].astype(str)
        pisa_filtered["year"] = pd.to_numeric(pisa_filtered["year"], errors="coerce").astype("Int64")
        pisa_filtered = pisa_filtered.dropna(subset=["entity", "year", "pisa_score"])

        temp_filtered = temp_all[["entity", "year", "value"]].rename(columns={"value": "temp"}).copy()
        temp_filtered["entity"] = temp_filtered["entity"].astype(str)
        temp_filtered["year"] = pd.to_numeric(temp_filtered["year"], errors="coerce").astype("Int64")
        temp_filtered = temp_filtered.dropna(subset=["entity", "year", "temp"])

        merged_user = pd.merge(temp_filtered, pisa_filtered, on=["entity", "year"], how="inner")
        if merged_user.empty:
            st.warning("ì„ íƒí•œ ê³¼ëª©ì— ëŒ€í•œ ê¸°ì˜¨Â·ì„±ì·¨ ê²°í•© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ê³¼ëª©ì„ ì„ íƒí•˜ì„¸ìš”.")
        else:
            countries = sorted(merged_user["entity"].unique().tolist())
            default_countries = ["South Korea"] if "South Korea" in countries else countries[:1]
            sel_countries = st.multiselect(
                "êµ­ê°€ ì„ íƒ (ê¸°ë³¸: ëŒ€í•œë¯¼êµ­)",
                countries,
                default=default_countries,
                key="user_line_countries",
            )

            if sel_countries:
                merged_user = merged_user[merged_user["entity"].isin(sel_countries)].copy()

            if merged_user.empty:
                st.info("ì„ íƒëœ êµ­ê°€ì— ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                year_min = int(merged_user["year"].min())
                year_max = int(merged_user["year"].max())
                if year_min == year_max:
                    year_range = (year_min, year_max)
                else:
                    default_start = max(year_min, year_max - 10)
                    year_range = st.slider(
                        "ì—°ë„ ë²”ìœ„",
                        min_value=year_min,
                        max_value=year_max,
                        value=(default_start, year_max),
                    )
                    merged_user = merged_user[(merged_user["year"] >= year_range[0]) & (merged_user["year"] <= year_range[1])]

                if merged_user.empty:
                    st.info("ì„ íƒí•œ ê¸°ê°„ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë²”ìœ„ë¥¼ ë‹¤ì‹œ ì„¤ì •í•˜ì„¸ìš”.")
                else:
                    chart_mode = st.radio(
                        "ê·¸ë˜í”„ ìœ í˜•",
                        ["í‰ê· ê¸°ì˜¨(Â°C)", "í•™ì—… ì„±ì·¨ ì ìˆ˜", "ê¸°ì˜¨Â·ì„±ì·¨ ì´ì¤‘ì¶•"],
                        index=2,
                    )

                    palette = px.colors.qualitative.Plotly
                    fig = go.Figure()

                    if chart_mode == "í‰ê· ê¸°ì˜¨(Â°C)":
                        for idx, country in enumerate(sel_countries):
                            country_df = merged_user[merged_user["entity"] == country].sort_values("year")
                            if len(country_df) < 2:
                                continue
                            fig.add_trace(
                                go.Scatter(
                                    x=country_df["year"],
                                    y=country_df["temp"],
                                    name=f"{country} ê¸°ì˜¨",
                                    mode="lines+markers",
                                    line=dict(color=palette[idx % len(palette)]),
                                )
                            )
                        fig.update_layout(
                            title="í‰ê· ê¸°ì˜¨ êº¾ì€ì„ ",
                            xaxis_title="ì—°ë„",
                            yaxis_title="í‰ê· ê¸°ì˜¨(Â°C)",
                        )
                    elif chart_mode == "í•™ì—… ì„±ì·¨ ì ìˆ˜":
                        for idx, country in enumerate(sel_countries):
                            country_df = merged_user[merged_user["entity"] == country].sort_values("year")
                            if len(country_df) < 2:
                                continue
                            fig.add_trace(
                                go.Scatter(
                                    x=country_df["year"],
                                    y=country_df["pisa_score"],
                                    name=f"{country} ì„±ì·¨",
                                    mode="lines+markers",
                                    line=dict(color=palette[idx % len(palette)]),
                                )
                            )
                        fig.update_layout(
                            title=f"PISA {sel_subject} ì ìˆ˜ êº¾ì€ì„ ",
                            xaxis_title="ì—°ë„",
                            yaxis_title="ì ìˆ˜",
                        )
                    else:
                        for idx, country in enumerate(sel_countries):
                            country_df = merged_user[merged_user["entity"] == country].sort_values("year")
                            if len(country_df) < 2:
                                continue
                            color_temp = palette[(2 * idx) % len(palette)]
                            color_score = palette[(2 * idx + 1) % len(palette)]
                            fig.add_trace(
                                go.Scatter(
                                    x=country_df["year"],
                                    y=country_df["temp"],
                                    name=f"{country} ê¸°ì˜¨",
                                    mode="lines+markers",
                                    line=dict(color=color_temp),
                                )
                            )
                            fig.add_trace(
                                go.Scatter(
                                    x=country_df["year"],
                                    y=country_df["pisa_score"],
                                    name=f"{country} ì„±ì·¨",
                                    mode="lines+markers",
                                    yaxis="y2",
                                    line=dict(color=color_score, dash="dash"),
                                )
                            )
                        fig.update_layout(
                            title=f"ê¸°ì˜¨Â·í•™ì—… ì„±ì·¨ ì´ì¤‘ì¶• êº¾ì€ì„  (ê³¼ëª©: {sel_subject})",
                            xaxis_title="ì—°ë„",
                            yaxis=dict(title="í‰ê· ê¸°ì˜¨(Â°C)", side="left"),
                            yaxis2=dict(title="í•™ì—… ì„±ì·¨ ì ìˆ˜", overlaying="y", side="right"),
                        )

                    if not fig.data:
                        st.info("í‘œì‹œí•  ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. êµ­ê°€/ê¸°ê°„ì„ ì¡°ì •í•´ ì£¼ì„¸ìš”.")
                    else:
                        fig.update_layout(legend=dict(orientation="h", y=-0.2))
                        st.plotly_chart(fig, use_container_width=True)

                    st.caption(f"ì„ íƒëœ ë°ì´í„° í¬ì¸íŠ¸: {len(merged_user)}ê°œ")


st.markdown(
    """
###### ë°ì´í„° ì¶œì²˜(ê³µì‹):
- NOAA COâ‚‚: https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_mm_mlo.csv
- NASA GISTEMP: https://data.giss.nasa.gov/gistemp/
- OWID COâ‚‚(ì „ì„¸ê³„): https://github.com/owid/co2-data
- ì˜¨ë„ ë³€í™”(êµ­ê°€ë³„, Berkeley Earth ì •ë¦¬): https://berkeleyearth.org/ (OWID ê°€ê³µë³¸)
"""
)

############################################
# Kaggle íƒ­ (ì„ íƒ, ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ì‹œ í‘œì‹œ)
############################################
if KAGGLE_AVAILABLE and rest:
    with rest[0]:
        st.subheader("Kaggle ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ë° ë¯¸ë¦¬ë³´ê¸°")
        st.caption("ì£¼ì˜: Kaggle ê³„ì •ì˜ API í† í°ì´ í•„ìš”í•©ë‹ˆë‹¤. ì´ ì•±ì€ ì—…ë¡œë“œëœ kaggle.jsonì„ ì„¸ì…˜ ì„ì‹œ í´ë”ë¡œ ì„¤ì •í•˜ì—¬ ì¸ì¦í•©ë‹ˆë‹¤.")

        # ì¸ì¦ ì¤€ë¹„: íŒŒì¼ ì—…ë¡œë“œ ë˜ëŠ” ê¸°ì¡´ Kaggle.json í™œìš©
        up = st.file_uploader("kaggle.json ì—…ë¡œë“œ", type=["json"], accept_multiple_files=False)
        kaggle_info = None
        config_dir = os.path.join(os.getcwd(), ".kaggle")
        os.makedirs(config_dir, exist_ok=True)
        config_path = os.path.join(config_dir, "kaggle.json")

        if up is not None:
            try:
                content = up.read()
                with open(config_path, "wb") as f:
                    f.write(content)
                try:
                    os.chmod(config_path, 0o600)
                except Exception:
                    pass
                os.environ["KAGGLE_CONFIG_DIR"] = config_dir
                kaggle_info = "ì—…ë¡œë“œí•œ kaggle.jsonìœ¼ë¡œ ì¸ì¦ ì„¤ì • ì™„ë£Œ"
            except Exception as e:
                st.error(f"kaggle.json ì €ì¥ ì‹¤íŒ¨: {e}")

        # ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ë£¨íŠ¸ì— Kaggle.jsonì´ ì¡´ì¬í•˜ë©´ ì‚¬ìš©
        if kaggle_info is None:
            repo_kaggle = os.path.join(os.getcwd(), "Kaggle.json")
            if os.path.exists(repo_kaggle):
                try:
                    with open(repo_kaggle, "rb") as src, open(config_path, "wb") as dst:
                        dst.write(src.read())
                    try:
                        os.chmod(config_path, 0o600)
                    except Exception:
                        pass
                    os.environ["KAGGLE_CONFIG_DIR"] = config_dir
                    kaggle_info = "ë¦¬í¬ì§€í† ë¦¬ì˜ Kaggle.jsonìœ¼ë¡œ ì¸ì¦ ì„¤ì • ì™„ë£Œ"
                except Exception as e:
                    st.warning(f"ë¦¬í¬ì§€í† ë¦¬ Kaggle.json ì‚¬ìš© ì‹¤íŒ¨: {e}")

        # í™˜ê²½ë³€ìˆ˜ ì¸ì¦ì´ ì´ë¯¸ ìˆëŠ” ê²½ìš° ì•ˆë‚´
        if kaggle_info is None and os.getenv("KAGGLE_USERNAME") and os.getenv("KAGGLE_KEY"):
            kaggle_info = "í™˜ê²½ë³€ìˆ˜(KAGGLE_USERNAME/KEY)ë¡œ ì¸ì¦ ì‚¬ìš©"

        if kaggle_info:
            st.success(kaggle_info)
        else:
            st.info("kaggle.json ì—…ë¡œë“œ ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.")

        dataset_slug = st.text_input("ë°ì´í„°ì…‹ ìŠ¬ëŸ¬ê·¸ (owner/dataset)", value="zynicide/wine-reviews")
        col_dl1, col_dl2 = st.columns([1, 1])
        with col_dl1:
            if st.button("íŒŒì¼ ëª©ë¡ ì¡°íšŒ"):
                try:
                    # Top-level optional import already set KAGGLE_AVAILABLE and kaggle_api
                    try:
                        kaggle_api.authenticate()  # type: ignore[attr-defined]
                    except Exception:
                        pass
                    files = kaggle_api.dataset_list_files(dataset_slug)  # type: ignore[union-attr]
                    st.write("íŒŒì¼ ëª©ë¡:", [f.name for f in files.files])
                except Exception as e:
                    st.error(f"íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        with col_dl2:
            if st.button("ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ"):
                try:
                    # ë‹¤ìš´ë¡œë“œ ë””ë ‰í† ë¦¬
                    dl_dir = os.path.join(os.getcwd(), "kaggle_data")
                    os.makedirs(dl_dir, exist_ok=True)
                    try:
                        kaggle_api.authenticate()  # type: ignore[attr-defined]
                    except Exception:
                        pass
                    kaggle_api.dataset_download_files(dataset_slug, path=dl_dir, unzip=True, quiet=False)  # type: ignore[union-attr]
                    st.success(f"ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {dl_dir}")
                except Exception as e:
                    st.error(f"ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")

        # CSV ë¯¸ë¦¬ë³´ê¸°
        dl_dir = os.path.join(os.getcwd(), "kaggle_data")
        if os.path.isdir(dl_dir):
            csv_files = [f for f in os.listdir(dl_dir) if f.lower().endswith(".csv")]
            if csv_files:
                sel_csv = st.selectbox("CSV íŒŒì¼ ì„ íƒ", csv_files)
                if sel_csv:
                    try:
                        df_k = pd.read_csv(os.path.join(dl_dir, sel_csv))
                        st.write("í–‰/ì—´:", df_k.shape)
                        st.dataframe(df_k.head(200))

                        # í‘œì¤€í™” ë§¤í•‘
                        st.markdown("#### í‘œì¤€ ìŠ¤í‚¤ë§ˆ ë§¤í•‘ (date/value/(ì„ íƒ)group)")
                        cols = df_k.columns.tolist()
                        date_col = st.selectbox("ë‚ ì§œ ì—´", ["(ì—†ìŒ)"] + cols, index=0)
                        value_col = st.selectbox("ê°’ ì—´", cols, index=min(1, len(cols)-1))
                        group_col = st.selectbox("ê·¸ë£¹ ì—´(ì„ íƒ)", ["(ì—†ìŒ)"] + cols, index=0)

                        def to_datetime_safe(s: pd.Series) -> pd.Series:
                            try:
                                return pd.to_datetime(s, errors="coerce")
                            except Exception:
                                return pd.to_datetime(pd.Series([None]*len(s)), errors="coerce")

                        std = pd.DataFrame()
                        if date_col != "(ì—†ìŒ)":
                            std["date"] = to_datetime_safe(df_k[date_col])
                        else:
                            std["date"] = pd.NaT
                        std["value"] = pd.to_numeric(df_k[value_col], errors="coerce")
                        if group_col != "(ì—†ìŒ)":
                            std["group"] = df_k[group_col].astype(str)
                        else:
                            std["group"] = "all"
                        std = std.dropna(subset=["value"]).copy()

                        st.markdown("#### í‘œì¤€í™” ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
                        st.dataframe(std.head(200))
                        download_button_for_df(std, "CSV ë‹¤ìš´ë¡œë“œ(í‘œì¤€í™”)", f"kaggle_standardized_{sel_csv}")

                        # ê°„ë‹¨ ì‹œê°í™”
                        if std["date"].notna().any():
                            st.markdown("#### ë¹ ë¥¸ ì„ ê·¸ë˜í”„")
                            fig_k = px.line(std.sort_values("date"), x="date", y="value", color="group")
                            fig_k.update_layout(xaxis_title="ë‚ ì§œ", yaxis_title="ê°’")
                            st.plotly_chart(fig_k, use_container_width=True)
                    except Exception as e:
                        st.error(f"CSV ë¯¸ë¦¬ë³´ê¸° ì‹¤íŒ¨: {e}")
            else:
                st.info("kaggle_data í´ë”ì— CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”.")
        else:
            st.info("ì•„ì§ ë‹¤ìš´ë¡œë“œ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”.")
