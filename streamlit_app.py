# streamlit_app.py
# -*- coding: utf-8 -*-
# ==========================================
# ì£¼ì œ: ê¸°ì˜¨ ìƒìŠ¹ê³¼ í•™ì—… ì„±ì·¨(ìˆ˜ë©´Â·ì„±ì ) ì—°ê´€ íƒêµ¬ ëŒ€ì‹œë³´ë“œ
# ì‹¤í–‰ í™˜ê²½: Streamlit + GitHub Codespaces (ë˜ëŠ” ë¡œì»¬)
# ------------------------------------------
# ê³µì‹ ê³µê°œ ë°ì´í„°(ì½”ë“œë¡œ ì§ì ‘ ì—°ê²°):
# - NASA GISTEMP v4 (ì „ì§€êµ¬ ì›”ë³„ ê¸°ì˜¨ ì´ìƒ, CSV)
#   í˜ì´ì§€: https://data.giss.nasa.gov/gistemp/
#   CSV:    https://data.giss.nasa.gov/gistemp/tabledata_v4/GLB.Ts+dSST.csv
#
# - World Bank EdStats Indicators API (PISA ì§€í‘œ ì˜ˆ: LO.PISA.MAT / LO.PISA.REA / LO.PISA.SCI)
#   ë¬¸ì„œ: https://datahelpdesk.worldbank.org/knowledgebase/articles/889392-about-the-indicators-api-documentation
#   ë°ì´í„°íƒìƒ‰: https://databank.worldbank.org/source/education-statistics-%5E-all-indicators
#
# ì¶”ê°€ ì°¸ê³  ìë£Œ(ì„¤ëª…/ë¬¸í—Œìš©, ë³¸ ì•±ì€ ì§ì ‘ API í˜¸ì¶œí•˜ì§€ ì•ŠìŒ):
# - ê¸°í›„ë³€í™”ì˜ ì›ì¸(ê¸°í›„ìœ„í‚¤, KMA): http://www.climate.go.kr/home/10_wiki/index.php/%EA%B8%B0%ED%9B%84%EB%B3%80%ED%99%94%EC%9D%98_%EC%9B%90%EC%9D%B8
# - í•œê²¨ë ˆ: ê¸°í›„ë³€í™”ê°€ ì—°ê°„ 44ì‹œê°„ì˜ ìˆ˜ë©´ì„ ì•—ì•„ê°”ë‹¤: https://www.hani.co.kr/arti/science/science_general/1046883.html
# - IPCC AR6 WGI SPM (PDF): https://www.ipcc.ch/report/ar6/wg1/downloads/report/IPCC_AR6_WGI_SPM.pdf
# - Park & Goodman (2023), Heat and Learning, PLOS Climate: https://journals.plos.org/climate/article?id=10.1371/journal.pclm.0000618
# - Goodman et al. (2018), Heat and Learning, NBER Working Paper 24639: https://www.nber.org/system/files/working_papers/w24639/w24639.pdf
# ==========================================

from __future__ import annotations

import io
import os
import time
import base64
from datetime import datetime
from zoneinfo import ZoneInfo

import numpy as np
import pandas as pd
import requests
from dateutil import parser as dup
from typing import Optional, Tuple, List

import streamlit as st
import plotly.express as px
from streamlit_echarts import st_echarts

import matplotlib
import matplotlib.pyplot as plt
import seaborn as sns
from zipfile import ZipFile

try:
    from kaggle.api.kaggle_api_extended import KaggleApi  # type: ignore
    KAGGLE_AVAILABLE = True
except Exception:
    KAGGLE_AVAILABLE = False

# statsmodels(ì˜µì…˜) ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€: seaborn regplot(lowess=True)ì— í•„ìš”
try:
    import statsmodels.api as sm  # noqa: F401
    LOWESS_AVAILABLE = True
except Exception:
    LOWESS_AVAILABLE = False

# ---------- í˜ì´ì§€ ì„¤ì • ----------
st.set_page_config(
    page_title="ê¸°ì˜¨ Ã— í•™ì—… ì„±ì·¨ ëŒ€ì‹œë³´ë“œ (ê³µê°œë°ì´í„° + ì‚¬ìš©ìë°ì´í„°)",
    layout="wide",
)

# ---------- ê³µí†µ ìƒìˆ˜ ----------
KST = ZoneInfo("Asia/Seoul")
TODAY_LOCAL = datetime.now(KST).date()  # â€œì˜¤ëŠ˜(ë¡œì»¬ ìì •)â€ ì´í›„ ë°ì´í„° ì œê±°ì— ì‚¬ìš©

REFERENCE_LINKS = [
    ("ê¸°í›„ìœ„í‚¤(ê¸°ìƒì²­)", "http://www.climate.go.kr/home/10_wiki/index.php/%EA%B8%B0%ED%9B%84%EB%B3%80%ED%99%94%EC%9D%98_%EC%9B%90%EC%9D%B8"),
    ("í•œê²¨ë ˆ(ìˆ˜ë©´ ì—°êµ¬ ê¸°ì‚¬)", "https://www.hani.co.kr/arti/science/science_general/1046883.html"),
    ("IPCC AR6 WGI SPM", "https://www.ipcc.ch/report/ar6/wg1/downloads/report/IPCC_AR6_WGI_SPM.pdf"),
    ("PLOS Climate: Heat and Learning (2023)", "https://journals.plos.org/climate/article?id=10.1371/journal.pclm.0000618"),
    ("NBER: Heat and Learning (2018)", "https://www.nber.org/system/files/working_papers/w24639/w24639.pdf"),
]

# ---------- í°íŠ¸ ì ìš© ----------
def try_apply_pretendard():
    """
    /fonts/Pretendard-Bold.ttf ê°€ ìˆìœ¼ë©´ Streamlit/Matplotlib/Plotly/EChartsì— ì ìš©.
    (ì¶”ê°€ í¸ì˜) /mnt/data/Pretendard_Bold.ttf ê²½ë¡œë„ ì‹œë„.
    ì—†ìœ¼ë©´ ìë™ ìƒëµ.
    """
    font_candidates = [
        "/fonts/Pretendard-Bold.ttf",
        "/mnt/data/Pretendard_Bold.ttf",  # ëŒ€í™”ì—ì„œ ì œê³µëœ ê²½ë¡œ ëŒ€ì‘
    ]
    font_path = next((p for p in font_candidates if os.path.exists(p)), None)
    if not font_path:
        return None

    # ì›¹(CSS) ì„ë² ë“œ
    try:
        with open(font_path, "rb") as f:
            font_b64 = base64.b64encode(f.read()).decode("utf-8")
        css = f"""
        <style>
        @font-face {{
            font-family: 'Pretendard';
            src: url(data:font/ttf;base64,{font_b64}) format('truetype');
            font-weight: 700;
            font-style: normal;
        }}
        html, body, [class*="css"] {{
            font-family: 'Pretendard', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Apple SD Gothic Neo', 'Noto Sans KR', 'Malgun Gothic', 'Helvetica Neue', Arial, sans-serif;
        }}
        </style>
        """
        st.markdown(css, unsafe_allow_html=True)
    except Exception:
        pass

    # Matplotlib/Seaborn
    try:
        from matplotlib import font_manager
        font_manager.fontManager.addfont(font_path)
        matplotlib.rcParams["font.family"] = "Pretendard"
    except Exception:
        pass

    return "Pretendard"

FONT_FAMILY = try_apply_pretendard()

# ---------- ìœ í‹¸ ----------
@st.cache_data(ttl=60 * 60)
def robust_get(url: str, params: dict | None = None, retry: int = 3, timeout: int = 20):
    """ê°„ë‹¨ ì¬ì‹œë„ GET. ì‹¤íŒ¨ ì‹œ raise."""
    last_err = None
    for i in range(retry):
        try:
            resp = requests.get(url, params=params, timeout=timeout)
            if resp.status_code == 200:
                return resp
            last_err = RuntimeError(f"HTTP {resp.status_code}")
        except Exception as e:
            last_err = e
        time.sleep(1.25 * (i + 1))
    raise last_err if last_err else RuntimeError("Unknown request error")

def drop_future(df: pd.DataFrame, date_col: str = "date") -> pd.DataFrame:
    """ì˜¤ëŠ˜(ë¡œì»¬ ìì •) ì´í›„ ìë£Œ ì œê±°"""
    df = df.copy()
    df[date_col] = pd.to_datetime(df[date_col]).dt.date
    return df[df[date_col] <= TODAY_LOCAL]

def to_csv_download(df: pd.DataFrame, filename: str):
    csv = df.to_csv(index=False).encode("utf-8-sig")
    st.download_button("ì „ì²˜ë¦¬ í‘œ CSV ë‹¤ìš´ë¡œë“œ", csv, file_name=filename, mime="text/csv")

# ---------- ê³µê°œ ë°ì´í„°: NASA GISTEMP ----------
@st.cache_data(ttl=60 * 60)
def load_nasa_gistemp_monthly() -> pd.DataFrame:
    """
    NASA GISTEMP v4 ì „ì§€êµ¬ ì›”ë³„ ê¸°ì˜¨ ì´ìƒ(Â°C) ë¡œë“œ â†’ long í¬ë§·(date, value, group).
    - í˜ì´ì§€: https://data.giss.nasa.gov/gistemp/
    - CSV:    https://data.giss.nasa.gov/gistemp/tabledata_v4/GLB.Ts+dSST.csv
    """
    url = "https://data.giss.nasa.gov/gistemp/tabledata_v4/GLB.Ts+dSST.csv"
    # ì‹¤íŒ¨ ëŒ€ë¹„ ì†Œí˜• ì˜ˆì‹œ(ì—°êµ¬ìš© ë¶€ì í•©)
    sample = """Year,Jan,Feb,Mar,Apr,May,Jun,Jul,Aug,Sep,Oct,Nov,Dec,J-D
2024,1.30,1.25,1.33,1.30,1.29,1.30,1.31,1.28,1.22,1.20,1.25,1.30,1.29
2025,1.22,1.19,1.27,1.24,1.21,1.18,,,,,,,,
"""
    try:
        resp = robust_get(url)
        raw = resp.text
    except Exception:
        st.warning("NASA GISTEMP API í˜¸ì¶œ ì‹¤íŒ¨ â†’ ì˜ˆì‹œ ë°ì´í„°ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤. (ì—°êµ¬/ì •ì±… íŒë‹¨ì— ì‚¬ìš© ê¸ˆì§€)")
        raw = sample

    # ì•/ë’¤ ì„¤ëª…í–‰ ì œê±° + í—¤ë” ì •ë ¬
    lines = [ln for ln in raw.splitlines() if ln.strip()]
    header_idx = 0
    for i, ln in enumerate(lines):
        if ln.lower().startswith("year"):
            header_idx = i
            break
    clean = "\n".join(lines[header_idx:])
    df = pd.read_csv(io.StringIO(clean))

    # ìš”ì•½ì—´ ì œê±°
    for col in ["J-D", "D-N", "DJF", "MAM", "JJA", "SON"]:
        if col in df.columns:
            df = df.drop(columns=[col])

    # long í¬ë§·
    df_long = df.melt(id_vars=["Year"], var_name="month", value_name="value")
    month_map = {m[:3].capitalize(): i for i, m in enumerate(
        ["Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"], start=1)}
    df_long["month"] = df_long["month"].str[:3].str.capitalize().map(month_map)
    # NASA ì›ë³¸ì—ëŠ” ê²°ì¸¡ì„ *** ë“±ìœ¼ë¡œ í‘œê¸°í•˜ëŠ” ê²½ìš°ê°€ ìˆì–´ ìˆ«ì ë³€í™˜ í•„ìš”
    df_long["value"] = pd.to_numeric(df_long["value"], errors="coerce")
    df_long = df_long.dropna(subset=["month", "value"])
    df_long["date"] = pd.to_datetime(dict(year=df_long["Year"], month=df_long["month"], day=1))
    out = df_long[["date", "value"]].sort_values("date").reset_index(drop=True)
    out["group"] = "Global anomaly (Â°C)"
    out = drop_future(out, "date")
    return out

# ---------- ê³µê°œ ë°ì´í„°: World Bank EdStats (PISA) ----------
@st.cache_data(ttl=60 * 60)
def load_worldbank_indicator(countries: list[str], indicator: str) -> pd.DataFrame:
    """
    World Bank Indicators APIì—ì„œ ì§€í‘œ ë¡œë“œ â†’ long í¬ë§·(date, value, group).
    - ë¬¸ì„œ: https://datahelpdesk.worldbank.org/knowledgebase/articles/889392-about-the-indicators-api-documentation
    - ì°¸ê³ : EdStats(êµìœ¡ì§€í‘œ) ë°ì´í„°ë±…í¬
    """
    base = "https://api.worldbank.org/v2/country/{}/indicator/{}"
    url = base.format(";".join([c.lower() for c in countries]), indicator)
    params = dict(format="json", per_page=20000)

    # ì‹¤íŒ¨ ëŒ€ë¹„ ì˜ˆì‹œ (ì—°êµ¬ìš© ë¶€ì í•©)
    sample_csv = """country,value,date
KOR,524,2022
KOR,526,2018
KOR,554,2012
JPN,536,2022
JPN,527,2018
USA,465,2022
USA,478,2018
"""
    try:
        resp = robust_get(url, params=params)
        js = resp.json()
        if not isinstance(js, list) or len(js) < 2 or js[1] is None:
            raise RuntimeError("Unexpected response")
        data = js[1]
        rows = []
        for row in data:
            val = row.get("value")
            yr = row.get("date")
            c = row.get("country", {}).get("id") or row.get("countryiso3code")
            if val is None or yr is None or c is None:
                continue
            rows.append(dict(country=c, value=float(val), date=pd.Timestamp(int(yr), 1, 1)))
        df = pd.DataFrame(rows)
        if df.empty:
            raise RuntimeError("Empty data")
    except Exception:
        st.warning("World Bank API í˜¸ì¶œ ì‹¤íŒ¨ â†’ PISA ì˜ˆì‹œ ë°ì´í„°ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤. (ì—°êµ¬/ì •ì±… íŒë‹¨ì— ì‚¬ìš© ê¸ˆì§€)")
        df = pd.read_csv(io.StringIO(sample_csv))
        df["date"] = pd.to_datetime(df["date"].astype(int).astype(str) + "-01-01")

    # ê°’ ì—´ì„ í™•ì‹¤íˆ ìˆ«ìí™”í•˜ì—¬ ì§‘ê³„/Arrow ì§ë ¬í™” ì˜¤ë¥˜ ë°©ì§€
    df["value"] = pd.to_numeric(df["value"], errors="coerce")
    df = df.dropna(subset=["value"]).reset_index(drop=True)

    df["group"] = df["country"]
    df = df[["date", "value", "group"]].sort_values(["group", "date"]).reset_index(drop=True)
    df = drop_future(df, "date")
    return df

# ---------- ì‚¬ìš©ì ë°ì´í„° í‘œì¤€í™” ----------
def standardize_user_df(df: pd.DataFrame, date_col: str, value_col: str, group_col: str | None) -> pd.DataFrame:
    out = df.copy()
    out[date_col] = pd.to_datetime(out[date_col], errors="coerce")
    out = out.dropna(subset=[date_col])
    out["date"] = out[date_col].dt.date
    out["value"] = pd.to_numeric(out[value_col], errors="coerce")
    out = out.dropna(subset=["value"])
    if group_col:
        out["group"] = out[group_col].astype(str)
    else:
        out["group"] = "default"
    out = out[["date", "value", "group"]].drop_duplicates()
    out = drop_future(out, "date")
    return out

# ---------- ë ˆì´ì•„ì›ƒ ----------
st.title("ğŸ“Š ê¸°ì˜¨ ìƒìŠ¹ Ã— í•™ì—… ì„±ì·¨ ëŒ€ì‹œë³´ë“œ")
st.caption("ê³µì‹ ê³µê°œ ë°ì´í„°(NASA / World Bank) + ì‚¬ìš©ì ì…ë ¥ ë°ì´í„°ë¥¼ ê°ê° ì‹œê°í™”í•©ë‹ˆë‹¤. (ë¡œì»¬ ê¸°ì¤€ ì˜¤ëŠ˜ ì´í›„ ë°ì´í„° ìë™ ì œê±°)")

# ----- ë³´ê³ ì„œ ì„¹ì…˜: ì„œë¡  / ë³¸ë¡  / ê²°ë¡  -----
st.markdown("## ì„œë¡  (ë¬¸ì œ ì œê¸°)")
st.markdown(
    """
ê¸°í›„ ë³€í™”ê°€ ê³„ì† ë¨ì— ë”°ë¼ í•™ìƒë“¤ì´ ê¸°ì˜¨ ë³€í™”ë¡œ ì¸í•´ í‰ì†Œ ë³´ë‹¤ ë” í° ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ ë°›ëŠ” ê²ƒì„ ëŠê¼ˆë‹¤. ì ì  ë†’ì•„ì§€ëŠ” ìµœê³ ê¸°ì˜¨ê³¼ ê¸¸ì–´ì§€ëŠ” ë”ìœ„ê°€ í•™ìƒë“¤ì˜ í•™ì—… ì„±ì ì— ì „í˜€ ë¬´ê´€í• ê¹Œ? í•˜ëŠ” ê¶ê¸ˆì¦ì„ ê°€ì§„ ìš°ë¦¬ëŠ” í•™ìƒë“¤ì˜ í•™ì—…ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì— ê´€í•œ ê¶ê¸ˆì¦ì„ í•´ì†Œí•˜ê³ , ì´ë¥¼ í•™ìƒë“¤ì—ê²Œ ì•Œë ¤ ê¸°ì˜¨ ìƒìŠ¹ ìƒí™©ì—ì„œ ì„±ì  ìƒìŠ¹ì„ ë•ê¸°ìœ„í•´ì„œ ì´ ì£¼ì œë¥¼ ì„ ì •í•´ ì—°êµ¬í•œë‹¤.

ì¸ë¥˜ í™œë™ìœ¼ë¡œ ë°œìƒí•œ ì§€êµ¬ ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œëŸ‰ì€ ì ì  ì¦ê°€í•˜ê³  ëŒ€ê¸° ì¤‘ ì´ì‚°í™”íƒ„ì†Œ ë†ë„ê°€  ë†’ì•„ì§€ë©° ì „ì§€êµ¬ í‰ê· ê¸°ì˜¨ë„ ë†’ì•„ì§€ê³  ìˆë‹¤. í™”ì„ ì—°ë£Œ ì‚¬ìš© ì¦ê°€ ë° ì‚°ì—… ë°œì „ê³¼ ì¸êµ¬ ì¦ê°€ë¡œ ì¸í•´ ê³¼ë„í•œ ì—ë„ˆì§€ ì†Œë¹„ê°€ ì¼ì–´ë‚˜ëŠ” ê²ƒì´ ì£¼ëœ ì›ì¸ì´ë‹¤.
"""
)

# ì„œë¡  ë°”ë¡œ ì•„ë˜: NASA ìµœê·¼ 24ê°œì›” ë¼ì¸ ì°¨íŠ¸
try:
    _df_temp_intro = load_nasa_gistemp_monthly()
    _df_recent = _df_temp_intro.tail(24)
    _fig_intro = px.line(_df_recent, x="date", y="value", color="group", markers=True,
                         title="ìµœê·¼ 24ê°œì›” ì „ì§€êµ¬ ê¸°ì˜¨ ì´ìƒ(Â°C)")
    if FONT_FAMILY:
        _fig_intro.update_layout(font_family="Pretendard")
    st.plotly_chart(_fig_intro, use_container_width=True)
except Exception as _e:
    st.warning(f"ì„œë¡  ì‹œê°í™” ë¡œë“œ ì‹¤íŒ¨: {_e}")

st.markdown("## ë³¸ë¡  1 (ë°ì´í„° ë¶„ì„)")
st.markdown(
    """
ì´ë²ˆ ì—°êµ¬ì—ì„œëŠ” ê¸°í›„ ë³€í™”ì™€ ìˆ˜ë©´ ì‹œê°„ì˜ ê´€ê³„ë¥¼ ë¶„ì„í•˜ì˜€ë‹¤. ìµœê·¼ ê¸°ì˜¨ ìƒìŠ¹ì€ ë‹¨ìˆœí•œ ìƒí™œ ë¶ˆí¸ì´ ì•„ë‹Œ ì²­ì†Œë…„ë“¤ì˜ ìˆ˜ë©´ íŒ¨í„´ì—ë„ í° ì˜í–¥ì„ ì£¼ê³  ìˆë‹¤. ì„  ê·¸ë˜í”„ë¥¼ í†µí•´ ë¶„ì„ í•œ ê²°ê³¼, ê¸°ì˜¨ì´ ë†’ì•„ì§ˆìˆ˜ë¡ í‰ê·  ìˆ˜ë©´ì‹œê°„ì´ ì ì°¨ ì¤„ì–´ë“œëŠ” ê²½í–¥ì´ í™•ì¸ë˜ì—ˆë‹¤.
íŠ¹íˆ ë”ìš´ ë‚ ì”¨ì—ëŠ” í•™ìƒë“¤ì´ ê¹Šì€ ì ì— ë“œëŠ” ì‹œê°„ì´ ì§§ì•„ì§€ê³ , ìì£¼ ê¹¨ëŠ” ê²½ìš°ê°€ ë§ì•„ ìˆ˜ë©´ì˜ ì§ˆ ë˜í•œ ë–¨ì–´ì§€ëŠ” ëª¨ìŠµì„ ë³´ì˜€ë‹¤. ì´ëŠ” ê³§ ìˆ˜ë©´ ë¶€ì¡±ìœ¼ë¡œ ì´ì–´ì§€ë©°, í•™ìŠµ íš¨ìœ¨ ì €í•˜ì™€ ì§‘ì¤‘ë ¥ ê°ì†Œì˜ ì›ì¸ìœ¼ë¡œ ì‘ìš©í•  ìˆ˜ ìˆë‹¤.
ë”°ë¼ì„œ ê¸°í›„ ë³€í™”ëŠ” ë‹¨ìˆœíˆ í™˜ê²½ì  ìœ„ê¸°ë§Œì´ ì•„ë‹ˆë¼, ì²­ì†Œë…„ë“¤ì˜ ìˆ˜ë©´ê³¼ í•™ìŠµ ëŠ¥ë ¥ì— ì˜í–¥ì„ ì£¼ëŠ” ì¤‘ìš”í•œ ìš”ì¸ì„ì„ ì•Œ ìˆ˜ ìˆë‹¤.
"""
)

# ë³¸ë¡ 1 ë°”ë¡œ ì•„ë˜: ìˆ«ìë§Œ ìˆëŠ” ë°ì´í„° â†’ ì¦‰ì‹œ ê·¸ë˜í”„
st.markdown("#### ìˆ«ì ë¦¬ìŠ¤íŠ¸ ì¦‰ì‹œ ì‹œê°í™”")
_num_text = st.text_area(
    "ìˆ«ì ë¦¬ìŠ¤íŠ¸ë¥¼ ì½¤ë§ˆ ë˜ëŠ” ì¤„ë°”ê¿ˆìœ¼ë¡œ ì…ë ¥ (ì˜ˆ: 3, 5, 2, 7)",
    height=100,
    placeholder="3, 5, 2, 7, 6, 4"
)
if _num_text.strip():
    try:
        _tokens = [t.strip() for t in _num_text.replace("\n", ",").split(",") if t.strip()]
        _values = [float(t) for t in _tokens]
        _df_nums = pd.DataFrame({"idx": range(1, len(_values)+1), "value": _values})
        _fig_line = px.line(_df_nums, x="idx", y="value", markers=True, title="ì…ë ¥ ìˆ«ì ë¼ì¸ ì°¨íŠ¸")
        if FONT_FAMILY:
            _fig_line.update_layout(font_family="Pretendard")
        st.plotly_chart(_fig_line, use_container_width=True)

        _fig_hist = px.histogram(_df_nums, x="value", nbins=min(20, max(5, len(_values)//2)), title="ë¶„í¬(íˆìŠ¤í† ê·¸ë¨)")
        if FONT_FAMILY:
            _fig_hist.update_layout(font_family="Pretendard")
        st.plotly_chart(_fig_hist, use_container_width=True)
    except Exception:
        st.info("ìˆ«ìë§Œ ì…ë ¥í•´ ì£¼ì„¸ìš”. ì˜ˆ: 1, 2, 3, 4")

# ë³¸ë¡ 1 ë°”ë¡œ ì•„ë˜: Kaggle.json ìë™ ì¸ì¦ + ê°„í¸ ë‹¤ìš´ë¡œë“œ/ê·¸ë˜í”„
if KAGGLE_AVAILABLE:
    st.markdown("#### Kaggle ë°ì´í„° ë¹ ë¥¸ ì‹œê°í™”")
    _auto_api = None
    try:
        _auto_api = KaggleApi()
        # ìë™ ê²½ë¡œ: ë£¨íŠ¸ì˜ Kaggle.json/kaggle.json ë˜ëŠ” ~/.kaggle/kaggle.json
        _candidates = [
            os.path.join(os.getcwd(), "Kaggle.json"),
            os.path.join(os.getcwd(), "kaggle.json"),
        ]
        _root_kg = next((p for p in _candidates if os.path.exists(p)), None)
        if _root_kg:
            tmp_dir = "/tmp/kaggle_creds_auto"
            os.makedirs(tmp_dir, exist_ok=True)
            cred_path = os.path.join(tmp_dir, "kaggle.json")
            with open(_root_kg, "rb") as src, open(cred_path, "wb") as dst:
                dst.write(src.read())
            os.chmod(cred_path, 0o600)
            os.environ["KAGGLE_CONFIG_DIR"] = tmp_dir
            _auto_api.authenticate()
        else:
            # í™ˆ ë””ë ‰í„°ë¦¬ ê¸°ë³¸ ì‚¬ìš©
            _auto_api.authenticate()
    except Exception as _e:
        st.info(f"Kaggle ìë™ ì¸ì¦ ìƒëµ: {_e}")
        _auto_api = None

    _col_k1, _col_k2 = st.columns([2, 1])
    with _col_k1:
        _ds_quick = st.text_input("Dataset slug (owner/dataset)", placeholder="zynicide/wine-reviews", key="quick_ds")
        _out_quick = st.text_input("ë‹¤ìš´ë¡œë“œ í´ë”", value="/tmp/kaggle_quick", key="quick_out")
        _btn_quick = st.button("Kaggleì—ì„œ ë°›ì•„ì„œ ê·¸ë¦¬ê¸°", disabled=not _auto_api or not _ds_quick)
        if _btn_quick and _auto_api:
            try:
                os.makedirs(_out_quick, exist_ok=True)
                _auto_api.dataset_download_files(_ds_quick, path=_out_quick, quiet=True, force=True)
                zips = [f for f in os.listdir(_out_quick) if f.endswith('.zip')]
                for z in zips:
                    with ZipFile(os.path.join(_out_quick, z), 'r') as zf:
                        zf.extractall(_out_quick)
                csvs = [os.path.join(_out_quick, f) for f in os.listdir(_out_quick) if f.lower().endswith('.csv')]
                if not csvs:
                    st.warning("CSV íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                else:
                    st.session_state["_kg_quick_csvs"] = csvs
                    st.success(f"ë‹¤ìš´ë¡œë“œ ì™„ë£Œ (CSV {len(csvs)}ê°œ)")
            except Exception as _e:
                st.error(f"Kaggle ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {_e}")
    with _col_k2:
        _csv_list = st.session_state.get("_kg_quick_csvs", [])
        if _csv_list:
            _pick = st.selectbox("CSV ì„ íƒ", _csv_list, key="quick_csv_pick")
            try:
                _dfk = pd.read_csv(_pick)
                st.dataframe(_dfk.head(20), width='stretch')
                cols = list(_dfk.columns)
                c1, c2, c3 = st.columns(3)
                date_col = c1.selectbox("ë‚ ì§œ ì—´", options=cols, key="quick_date")
                value_col = c2.selectbox("ê°’ ì—´", options=cols, key="quick_value")
                group_col_opt = c3.selectbox("ê·¸ë£¹ ì—´(ì„ íƒ)", options=["<ì—†ìŒ>"] + cols, key="quick_group")
                group_col = None if group_col_opt == "<ì—†ìŒ>" else group_col_opt
                std = standardize_user_df(_dfk, date_col, value_col, group_col)
                st.success("ì „ì²˜ë¦¬ ì™„ë£Œ")
                fig_quick = px.line(std, x="date", y="value", color="group", markers=True, title="Kaggle ë°ì´í„° ë¼ì¸ ì°¨íŠ¸")
                if FONT_FAMILY:
                    fig_quick.update_layout(font_family="Pretendard")
                st.plotly_chart(fig_quick, use_container_width=True)
            except Exception as _e:
                st.error(f"CSV íŒŒì‹± ì‹¤íŒ¨: {_e}")

st.markdown("## ë³¸ë¡  2 (ì›ì¸ ë° ì˜í–¥ íƒêµ¬)")
st.markdown(
    """
ê¸°ì˜¨ ë³€í™”ì™€ ì„±ì ì€ ì‹¤ì œë¡œ ìƒê´€ê´€ê³„ë¥¼ ê°€ì§„ë‹¤. ì•„ë˜ì˜ ë§‰ëŒ€ ê·¸ë˜í”„ì™€ ì‚°ì ë„ë¥¼ ì‚´í”¼ë©´ ë” ì •í™•íˆ ì•Œ ìˆ˜ ìˆë‹¤.

ìœ„ì˜ ë§‰ëŒ€ê·¸ë˜í”„ëŠ” ì „ ì„¸ê³„ ë‹¤ì–‘í•œ ì—°êµ¬ì—ì„œ ë³´ê³ ëœ ê¸°ì˜¨ ìƒìŠ¹ê³¼ í•™ì—… ì„±ì  ë³€í™”ì˜ ìƒê´€ê´€ê³„ë¥¼ ë¹„êµí•œ ê²ƒì´ë‹¤. ê·¸ë˜í”„ì—ì„œ ë³¼ ìˆ˜ ìˆë“¯ì´, ëŒ€ë¶€ë¶„ì˜ ì—°êµ¬ì—ì„œ ê¸°ì˜¨ì´ ì¼ì • ìˆ˜ì¤€ ì´ìƒ ìƒìŠ¹í•˜ë©´ í•™ìƒë“¤ì˜ ì„±ì ì´ í‘œì¤€í¸ì°¨ ë‹¨ìœ„ë¡œ ê°ì†Œí•˜ëŠ” ê²½í–¥ì´ ë‚˜íƒ€ë‚œë‹¤.
íŠ¹íˆ OECD êµ­ì œí•™ì—…ì„±ì·¨ë„ í‰ê°€(PISA)ë¥¼ í™œìš©í•œ 58ê°œêµ­ ë¶„ì„ì—ì„œëŠ” ê³ ì˜¨ ë…¸ì¶œì´ ëˆ„ì ë ìˆ˜ë¡ ì„±ì ì´ í¬ê²Œ í•˜ë½í•˜ëŠ” ê²°ê³¼ê°€ í™•ì¸ë˜ì—ˆë‹¤. ë¯¸êµ­ê³¼ ë‰´ìš•ì˜ ì‚¬ë¡€ ë˜í•œ ì‹œí—˜ ë‹¹ì¼ ê¸°ì˜¨ì´ ë†’ì„ìˆ˜ë¡ í•™ìƒë“¤ì˜ ì„±ì ê³¼ í•©ê²©ë¥ ì´ ìœ ì˜í•˜ê²Œ ë–¨ì–´ì¡Œë‹¤. í•œêµ­ì˜ ê²½ìš° ë‹¨ì¼ ê³ ì˜¨ì¼ì˜ íš¨ê³¼ëŠ” ë¹„êµì  ì‘ì§€ë§Œ, 34â„ƒ ì´ìƒì˜ ë‚ ì´ ëˆ„ì ë ìˆ˜ë¡ ìˆ˜í•™ê³¼ ì˜ì–´ ì„±ì ì´ ì ì°¨ ê°ì†Œí•˜ëŠ” ê²½í–¥ì„ ë³´ì˜€ë‹¤.
ì´ì²˜ëŸ¼ ê³ ì˜¨ í™˜ê²½ì€ ë‹¨ìˆœí•œ ë¶ˆì¾Œê°ì„ ë„˜ì–´ í•™ì—… ì„±ì·¨ì—ë„ ë¶€ì •ì ì¸ ì˜í–¥ì„ ë¯¸ì¹˜ë©°, íŠ¹íˆ ëˆ„ì  íš¨ê³¼ê°€ ì¥ê¸°ì ì¸ ì„±ì  ì €í•˜ë¡œ ì´ì–´ì§ˆ ìˆ˜ ìˆìŒì„ ì‹œì‚¬í•œë‹¤.

ìœ„ ê·¸ë¦¼ì€ 2012ë…„ PISA(íŒ¨ë„ A) ë˜ëŠ” SEDA(íŒ¨ë„ B) ìˆ˜í•™ í‰ê·  ì ìˆ˜ì™€ êµ­ê°€ ë˜ëŠ” ë¯¸êµ­ ì¹´ìš´í‹°ë³„ ì—°í‰ê·  ê¸°ì˜¨ì˜ ì‚°ì ë„ì´ë‹¤.

ì—°í‰ê·  ê¸°ì˜¨ì€ 1980ë…„ë¶€í„° 2011ë…„ê¹Œì§€ ì¸¡ì •ë˜ì—ˆê³ , íŒ¨ë„ BëŠ” í‰ê·  ê¸°ì˜¨ ë¶„í¬ì˜ ë°±ë¶„ìœ„ ë³„ë¡œ í‘œì¤€í™”ëœ 3~8í•™ë…„ ìˆ˜í•™ ì ìˆ˜(2009~2013ë…„)ì˜ êµ¬ê°„ë³„ ë°±ë¶„ìœ„ ê·¸ë˜í”„ì´ë‹¤. ì ìˆ˜ëŠ” ê³¼ëª©, í•™ë…„, ì—°ë„ë³„ë¡œ í‘œì¤€í™”ëœ ì ìˆ˜ë¥¼ ì‚¬ìš©í•œë‹¤.

ì´ ì‚°ì ë„ëŠ” ê°„ë‹¨íˆ ë§í•˜ìë©´ ë¯¸êµ­ í•™ìƒë“¤ì˜ ìˆ˜í•™ ì„±ì ì´ ê¸°ì˜¨ì— ë”°ë¼ ì–´ë–»ê²Œ ë³€í™”í•˜ëŠ”ì§€ ë³´ì—¬ì¤€ë‹¤. ìœ„ ê·¸ë˜í”„ëŠ” ê¸°ì˜¨ì´ ë†’ì•„ì§ˆ ìˆ˜ë¡ ì„±ì ì´ í•˜ë½í•˜ëŠ” ê²½í–¥ì„ ë©´ë°€íˆ ë³´ì—¬ì£¼ê³  ìˆë‹¤. ë”°ë¼ì„œ ìš°ë¦¬ëŠ” ê¸°ì˜¨ ìƒìŠ¹ì´ í•™ìƒë“¤ì˜ ì„±ì ì— ë°€ì ‘í•œ ì—°ê´€ì„ ê°€ì§„ë‹¤ëŠ” ì‚¬ì‹¤ì„ ì•Œ ìˆ˜ ìˆë‹¤.
"""
)

# ë³¸ë¡ 2 ë°”ë¡œ ì•„ë˜: PISA Ã— ê¸°ì˜¨ ìƒê´€ ì‚°ì ë„(ìš”ì•½)
try:
    _countries_default = ["KOR", "JPN", "USA"]
    _indicator_default = "LO.PISA.MAT"
    _country_pick = st.selectbox("êµ­ê°€ ì„ íƒ (ìš”ì•½ ì‚°ì ë„)", _countries_default, index=0, key="intro_country")
    _df_pisa_intro = load_worldbank_indicator(_countries_default, _indicator_default)
    if not _df_pisa_intro.empty:
        _annual_temp = load_nasa_gistemp_monthly().assign(year=lambda d: pd.to_datetime(d["date"]).dt.year) \
                                               .groupby("year", as_index=False)["value"].mean() \
                                               .rename(columns={"value": "temp_anom"})
        _pisa_focus = _df_pisa_intro[_df_pisa_intro["group"] == _country_pick].copy()
        _pisa_focus["year"] = pd.to_datetime(_pisa_focus["date"]).dt.year
        _merged_intro = pd.merge(_pisa_focus[["year", "value"]], _annual_temp, on="year", how="inner")
        _merged_intro = _merged_intro.rename(columns={"value": "pisa_score"})
        _series_intro = [[float(r["temp_anom"]), float(r["pisa_score"])] for _, r in _merged_intro.iterrows()]
        _opt_intro = {
            "title": {"text": f"{_country_pick}: ê¸°ì˜¨ ì´ìƒ vs PISA(ìš”ì•½)", "left": "center",
                      "textStyle": {"fontFamily": FONT_FAMILY or "inherit"}},
            "tooltip": {"trigger": "item"},
            "xAxis": {"name": "ì—°í‰ê·  ê¸°ì˜¨ ì´ìƒ(Â°C)", "nameLocation": "middle", "nameGap": 28},
            "yAxis": {"name": "PISA í‰ê·  ì ìˆ˜", "nameLocation": "middle", "nameGap": 28},
            "series": [{"type": "scatter", "data": _series_intro, "symbolSize": 10}],
        }
        st_echarts(options=_opt_intro, height="360px")
    else:
        st.info("ìš”ì•½ ì‚°ì ë„ë¥¼ í‘œì‹œí•  PISA ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
except Exception as _e:
    st.warning(f"ë³¸ë¡ 2 ìš”ì•½ ì‚°ì ë„ ìƒì„± ì‹¤íŒ¨: {_e}")

tab_pub, tab_user = st.tabs(["ğŸŒ ê³µì‹ ê³µê°œ ë°ì´í„° ëŒ€ì‹œë³´ë“œ", "ğŸ§‘â€ğŸ’» ì‚¬ìš©ì ì…ë ¥ ëŒ€ì‹œë³´ë“œ"])
tab_kaggle = None
if KAGGLE_AVAILABLE:
    tab_pub, tab_user, tab_kaggle = st.tabs(["ğŸŒ ê³µì‹ ê³µê°œ ë°ì´í„° ëŒ€ì‹œë³´ë“œ", "ğŸ§‘â€ğŸ’» ì‚¬ìš©ì ì…ë ¥ ëŒ€ì‹œë³´ë“œ", "ğŸ“¦ Kaggle ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°"])

# ==========================
# 1) ê³µì‹ ê³µê°œ ë°ì´í„°
# ==========================
with tab_pub:
    st.subheader("â‘  ì „ì§€êµ¬ ì›”ë³„ ê¸°ì˜¨ ì´ìƒ (NASA GISTEMP v4)")
    colA, colB = st.columns([2, 1], gap="large")

    with colA:
        df_temp = load_nasa_gistemp_monthly()
        st.write("ë°ì´í„° í‘œ (ì „ì²˜ë¦¬Â·í‘œì¤€í™” ì™„ë£Œ)")
        st.dataframe(df_temp.tail(24), width='stretch')

        fig = px.line(
            df_temp, x="date", y="value", color="group",
            title="ì „ì§€êµ¬ ê¸°ì˜¨ ì´ìƒ(ì›”ë³„, Â°C)"
        )
        if FONT_FAMILY:
            fig.update_layout(font_family="Pretendard")
        st.plotly_chart(fig, use_container_width=True)
        to_csv_download(df_temp, "nasa_gistemp_monthly.csv")

    with colB:
        annual = df_temp.copy()
        annual["value"] = pd.to_numeric(annual["value"], errors="coerce")
        annual = annual.dropna(subset=["value"])  # ì•ˆì „ ì²˜ë¦¬
        annual["year"] = pd.to_datetime(annual["date"]).dt.year
        annual = annual.groupby(["year", "group"], as_index=False)["value"].mean()
        fig2 = px.bar(annual.tail(30), x="year", y="value", color="group", title="ìµœê·¼ 30ë…„ ì—°í‰ê·  ì´ìƒ(Â°C)")
        if FONT_FAMILY:
            fig2.update_layout(font_family="Pretendard")
        st.plotly_chart(fig2, use_container_width=True)

    fig3, ax = plt.subplots(figsize=(5.6, 3.2))
    # statsmodels ì—†ê±°ë‚˜ ì˜¤ë¥˜ ì‹œ í´ë°±: ì¼ë°˜ íšŒê·€ì„ ìœ¼ë¡œ í‘œì‹œ
    try:
        sns.regplot(data=annual, x="year", y="value", lowess=LOWESS_AVAILABLE, ax=ax)
    except Exception as e:
        sns.regplot(data=annual, x="year", y="value", lowess=False, ax=ax)
        st.warning("LOWESS ì„ ì„ ê·¸ë¦´ ìˆ˜ ì—†ì–´ ì¼ë°˜ íšŒê·€ì„ ìœ¼ë¡œ ëŒ€ì²´í–ˆìŠµë‹ˆë‹¤. (statsmodels í•„ìš”)")
    ax.set_title("ì—°í‰ê·  ì´ìƒ ì¶”ì„¸(íšŒê·€/LOWESS)")
    st.pyplot(fig3, clear_figure=True)

    st.markdown("> ì¶œì²˜: NASA GISTEMP v4 (Tables of Global and Hemispheric Monthly Means, Global-mean monthly CSV)")

    st.markdown("---")
    st.subheader("â‘¡ PISA í‰ê·  ì„±ì·¨ (World Bank EdStats, Indicators API)")
    countries_default = ["KOR", "JPN", "USA"]
    c_sel = st.multiselect("êµ­ê°€(ISO3, ì—¬ëŸ¬ ê°œ ì„ íƒ ê°€ëŠ¥)",
                           options=countries_default + ["DEU", "CHN", "GBR", "FRA", "CAN", "AUS", "NZL", "SGP", "FIN"],
                           default=countries_default)
    indicator = st.selectbox(
        "ì§€í‘œ ì„ íƒ (EdStats)",
        options=["LO.PISA.MAT", "LO.PISA.REA", "LO.PISA.SCI"],
        index=0,
        help="World Bank Indicators APIì˜ EdStats ì§€í‘œ ì½”ë“œ(êµ­ê°€/ë…„ë„ ê°€ìš©ì„±ì€ ì°¨ì´ê°€ ìˆì„ ìˆ˜ ìˆìŒ).",
    )
    df_pisa = load_worldbank_indicator(c_sel or countries_default, indicator)

    c1, c2 = st.columns([2, 1], gap="large")
    with c1:
        fig4 = px.line(df_pisa, x="date", y="value", color="group", markers=True,
                       title=f"{indicator} ì—°ë„ë³„ ì¶”ì´ (PISA í‰ê·  ì ìˆ˜)")
        if FONT_FAMILY:
            fig4.update_layout(font_family="Pretendard")
        st.plotly_chart(fig4, use_container_width=True)
        st.dataframe(df_pisa.head(20), width='stretch')
        to_csv_download(df_pisa, f"worldbank_{indicator.lower()}.csv")

    with c2:
        if not df_pisa.empty:
            annual_temp = load_nasa_gistemp_monthly().assign(year=lambda d: pd.to_datetime(d["date"]).dt.year) \
                                                     .groupby("year", as_index=False)["value"].mean() \
                                                     .rename(columns={"value": "temp_anom"})
            focus = (c_sel or countries_default)[0]
            pisa_focus = df_pisa[df_pisa["group"] == focus].copy()
            pisa_focus["year"] = pd.to_datetime(pisa_focus["date"]).dt.year
            merged = pd.merge(pisa_focus[["year", "value"]], annual_temp, on="year", how="inner")
            merged = merged.rename(columns={"value": "pisa_score"})
            st.write(f"ìƒê´€ ë³´ê¸°: {focus} (PISA) Ã— ì „ì§€êµ¬ ì—°í‰ê·  ê¸°ì˜¨ ì´ìƒ")
            series_data = [[float(r["temp_anom"]), float(r["pisa_score"])] for _, r in merged.iterrows()]
            option = {
                "title": {"text": f"{focus}: ê¸°ì˜¨ ì´ìƒ vs PISA", "left": "center",
                          "textStyle": {"fontFamily": FONT_FAMILY or "inherit"}},
                "tooltip": {"trigger": "item"},
                "xAxis": {"name": "ì—°í‰ê·  ê¸°ì˜¨ ì´ìƒ(Â°C)", "nameLocation": "middle", "nameGap": 28},
                "yAxis": {"name": "PISA í‰ê·  ì ìˆ˜", "nameLocation": "middle", "nameGap": 28},
                "series": [{"type": "scatter", "data": series_data, "symbolSize": 10}],
            }
            st_echarts(options=option, height="350px")
            st.dataframe(merged.sort_values("year", ascending=False), width='stretch')
        else:
            st.info("í‘œì‹œí•  PISA ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    with st.expander("ğŸ“š ì°¸ê³  ìë£Œ ë§í¬"):
        st.markdown("\n".join([f"- [{name}]({url})" for name, url in REFERENCE_LINKS]))

# ==========================
# 2) ì‚¬ìš©ì ì…ë ¥ ëŒ€ì‹œë³´ë“œ
# ==========================
with tab_user:
    st.subheader("CSV ì—…ë¡œë“œ/ë¶™ì—¬ë„£ê¸° â†’ í‘œì¤€í™” â†’ ì‹œê°í™”")

    up_col, paste_col = st.columns(2)
    with up_col:
        file = st.file_uploader("CSV ì—…ë¡œë“œ (UTF-8 ê¶Œì¥)", type=["csv"])
        df_user = None
        if file:
            try:
                df_user = pd.read_csv(file)
            except Exception:
                st.error("CSV ì½ê¸° ì‹¤íŒ¨: ì¸ì½”ë”©/êµ¬ë¶„ì í™•ì¸")
    with paste_col:
        txt = st.text_area("CSV ë‚´ìš© ë¶™ì—¬ë„£ê¸° (ì˜µì…˜)", height=160,
                           placeholder="date,value,group\n2024-06-01,7.3,A\n2024-06-02,6.9,A\n...")
        if txt.strip() and df_user is None:
            try:
                df_user = pd.read_csv(io.StringIO(txt))
            except Exception:
                st.error("ë¶™ì—¬ë„£ê¸° CSV íŒŒì‹± ì‹¤íŒ¨")

    if df_user is not None and not df_user.empty:
        st.write("ì›ë³¸ ë¯¸ë¦¬ë³´ê¸°")
        st.dataframe(df_user.head(20), width='stretch')

        cols = list(df_user.columns)
        c1, c2, c3 = st.columns(3)
        date_col = c1.selectbox("ë‚ ì§œ ì—´ ì„ íƒ", options=cols)
        value_col = c2.selectbox("ê°’ ì—´ ì„ íƒ", options=cols)
        group_col_opt = c3.selectbox("ê·¸ë£¹ ì—´ ì„ íƒ(ì„ íƒ)", options=["<ì—†ìŒ>"] + cols)
        group_col = None if group_col_opt == "<ì—†ìŒ>" else group_col_opt

        std = standardize_user_df(df_user, date_col, value_col, group_col)
        st.success("ì „ì²˜ë¦¬ ì™„ë£Œ (ê²°ì¸¡/í˜•ë³€í™˜/ì¤‘ë³µ ì œê±° + ë¯¸ë˜ë°ì´í„° ì œê±°)")
        st.dataframe(std.head(30), width='stretch')
        to_csv_download(std, "user_standardized.csv")

        st.markdown("#### ì‹œê°í™”")
        t1, t2 = st.columns([2, 1], gap="large")
        with t1:
            figu = px.line(std, x="date", y="value", color="group", markers=True, title="ë¼ì¸ ì°¨íŠ¸")
            if FONT_FAMILY:
                figu.update_layout(font_family="Pretendard")
            st.plotly_chart(figu, use_container_width=True)
        with t2:
            agg_unit = st.selectbox("ì§‘ê³„ ë‹¨ìœ„", ["ì¼", "ì›”(í‰ê· )", "ì—°(í‰ê· )"], index=1)
            tmp = std.copy()
            if agg_unit == "ì›”(í‰ê· )":
                tmp["date"] = pd.to_datetime(tmp["date"]).dt.to_period("M").dt.to_timestamp()
            elif agg_unit == "ì—°(í‰ê· )":
                tmp["date"] = pd.to_datetime(tmp["date"]).dt.to_period("Y").dt.to_timestamp()
            agg = tmp.groupby(["date", "group"], as_index=False)["value"].mean()
            figb = px.bar(agg, x="date", y="value", color="group", title=f"ì§‘ê³„ ë§‰ëŒ€ ({agg_unit})")
            if FONT_FAMILY:
                figb.update_layout(font_family="Pretendard")
            st.plotly_chart(figb, use_container_width=True)

        st.markdown("#### ì‚°ì ë„(ê·¸ë£¹ë³„) + ê°„ë‹¨ íšŒê·€ì„ ")
        g_list = sorted(std["group"].unique())
        g_pick = st.selectbox("ê·¸ë£¹ ì„ íƒ", g_list)
        sub = std[std["group"] == g_pick].copy()
        sub["x"] = pd.to_datetime(sub["date"]).map(pd.Timestamp.toordinal)
        if len(sub) >= 2:
            m, b = np.polyfit(sub["x"], sub["value"], 1)
            sub = sub.sort_values("x")
            sub["trend"] = m * sub["x"] + b
            series_scatter = [[int(x), float(y)] for x, y in zip(sub["x"], sub["value"])]
            series_line = [[int(x), float(y)] for x, y in zip(sub["x"], sub["trend"])]
            option2 = {
                "title": {"text": f"{g_pick} ì‚°ì /íšŒê·€", "left": "center",
                          "textStyle": {"fontFamily": FONT_FAMILY or "inherit"}},
                "tooltip": {"trigger": "axis"},
                "xAxis": {"type": "value", "axisLabel": {"formatter": "{value} (ordinal date)"}},
                "yAxis": {"type": "value", "name": "value"},
                "series": [
                    {"type": "scatter", "name": "data", "data": series_scatter, "symbolSize": 9},
                    {"type": "line", "name": "trend", "data": series_line, "smooth": True},
                ],
                "legend": {"top": 0},
            }
            st_echarts(options=option2, height="360px")
        else:
            st.info("ì‚°ì ë„/íšŒê·€ë¥¼ ìœ„í•´ì„œëŠ” ìµœì†Œ 2ê°œ ì´ìƒì˜ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    else:
        st.info("CSV ì—…ë¡œë“œ ë˜ëŠ” ë¶™ì—¬ë„£ê¸°ë¡œ ì‚¬ìš©ì ë°ì´í„°ë¥¼ ì œê³µí•˜ì„¸ìš”.")

# ==========================
# 3) Kaggle ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° (ì˜µì…˜)
# ==========================
if KAGGLE_AVAILABLE and tab_kaggle is not None:
    with tab_kaggle:
        st.subheader("Kaggle ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ â†’ CSV ì„ íƒ â†’ í‘œì¤€í™”")
        st.caption("ìê²© ì¦ëª…ì€ ì„¸ì…˜ ë‚´ ë©”ëª¨ë¦¬ ë˜ëŠ” ~/.kaggle/kaggle.jsonì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")

        col_auth, col_dl = st.columns([1, 2])
        with col_auth:
            st.markdown("#### 1) ì¸ì¦")
            use_file = st.toggle("kaggle.json ì—…ë¡œë“œ", value=False, help="ì²´í¬ ì‹œ ì•„ë˜ ì—…ë¡œë” ì‚¬ìš©. ë¯¸ì²´í¬ ì‹œ ì‚¬ìš©ì/í‚¤ ì…ë ¥")
            kaggle_json = None
            username: Optional[str] = None
            key: Optional[str] = None
            if use_file:
                up = st.file_uploader("kaggle.json ì—…ë¡œë“œ", type=["json"])
                if up is not None:
                    kaggle_json = up.read()
            else:
                username = st.text_input("Kaggle Username", value=os.environ.get("KAGGLE_USERNAME", ""))
                key = st.text_input("Kaggle Key", type="password", value=os.environ.get("KAGGLE_KEY", ""))

            def do_auth() -> Tuple[Optional[KaggleApi], Optional[str]]:
                try:
                    api = KaggleApi()
                    if kaggle_json:
                        # ì„¸ì…˜ ì„ì‹œ íŒŒì¼ì— ì €ì¥í•˜ì—¬ ì¸ì¦
                        tmp_dir = st.session_state.get("_kg_tmp", None)
                        if not tmp_dir:
                            tmp_dir = "/tmp/kaggle_creds"
                            os.makedirs(tmp_dir, exist_ok=True)
                            st.session_state["_kg_tmp"] = tmp_dir
                        cred_path = os.path.join(tmp_dir, "kaggle.json")
                        with open(cred_path, "wb") as f:
                            f.write(kaggle_json)
                        os.chmod(cred_path, 0o600)
                        os.environ["KAGGLE_CONFIG_DIR"] = tmp_dir
                        api.authenticate()
                        return api, cred_path
                    elif username and key:
                        os.environ["KAGGLE_USERNAME"] = username
                        os.environ["KAGGLE_KEY"] = key
                        api.authenticate()
                        return api, None
                    else:
                        return None, None
                except Exception as e:
                    st.error(f"ì¸ì¦ ì‹¤íŒ¨: {e}")
                    return None, None

            api, cred_file = do_auth()
            if api:
                st.success("Kaggle ì¸ì¦ ì„±ê³µ")
            else:
                st.info("ì¸ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤. ì¢Œì¸¡ì—ì„œ kaggle.json ì—…ë¡œë“œ ë˜ëŠ” ê³„ì •/í‚¤ ì…ë ¥ í›„ ì¬ì‹œë„í•˜ì„¸ìš”.")

        with col_dl:
            st.markdown("#### 2) ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ")
            ds = st.text_input("Dataset slug (owner/dataset)", placeholder="zynicide/wine-reviews")
            out_dir = st.text_input("ë‹¤ìš´ë¡œë“œ í´ë”", value="/tmp/kaggle_downloads")
            dl_btn = st.button("ë‹¤ìš´ë¡œë“œ", disabled=not api or not ds)
            csv_files: List[str] = []
            selected_csv: Optional[str] = None
            if dl_btn and api:
                try:
                    os.makedirs(out_dir, exist_ok=True)
                    api.dataset_download_files(ds, path=out_dir, quiet=False, force=True)
                    # zip íŒŒì¼ ì°¾ê¸° í›„ í•´ì œ
                    zips = [f for f in os.listdir(out_dir) if f.endswith('.zip')]
                    for z in zips:
                        with ZipFile(os.path.join(out_dir, z), 'r') as zf:
                            zf.extractall(out_dir)
                    csv_files = [os.path.join(out_dir, f) for f in os.listdir(out_dir) if f.lower().endswith('.csv')]
                    st.session_state["_kaggle_csvs"] = csv_files
                    st.success(f"ë‹¤ìš´ë¡œë“œ ì™„ë£Œ. CSV {len(csv_files)}ê°œ ë°œê²¬")
                except Exception as e:
                    st.error(f"ë‹¤ìš´ë¡œë“œ/í•´ì œ ì‹¤íŒ¨: {e}")

            csv_files = st.session_state.get("_kaggle_csvs", [])
            if csv_files:
                selected_csv = st.selectbox("CSV ì„ íƒ", csv_files)
                if selected_csv and os.path.exists(selected_csv):
                    try:
                        df_k = pd.read_csv(selected_csv)
                        st.write("ë¯¸ë¦¬ë³´ê¸°")
                        st.dataframe(df_k.head(30), width='stretch')
                        # ì—´ ë§¤í•‘ â†’ ê¸°ì¡´ í‘œì¤€í™” í•¨ìˆ˜ ì¬ì‚¬ìš©
                        cols = list(df_k.columns)
                        c1, c2, c3 = st.columns(3)
                        date_col = c1.selectbox("ë‚ ì§œ ì—´ ì„ íƒ", options=cols, key="kg_date")
                        value_col = c2.selectbox("ê°’ ì—´ ì„ íƒ", options=cols, key="kg_value")
                        group_col_opt = c3.selectbox("ê·¸ë£¹ ì—´ ì„ íƒ(ì„ íƒ)", options=["<ì—†ìŒ>"] + cols, key="kg_group_opt")
                        group_col = None if group_col_opt == "<ì—†ìŒ>" else group_col_opt

                        std = standardize_user_df(df_k, date_col, value_col, group_col)
                        st.success("í‘œì¤€í™” ì™„ë£Œ")
                        st.dataframe(std.head(30), width='stretch')
                        to_csv_download(std, os.path.basename(selected_csv).replace('.csv', '_standardized.csv'))

                        # ì¬ì‚¬ìš© ì‹œê°í™”
                        st.markdown("#### ì‹œê°í™”")
                        figu = px.line(std, x="date", y="value", color="group", markers=True, title="ë¼ì¸ ì°¨íŠ¸")
                        if FONT_FAMILY:
                            figu.update_layout(font_family="Pretendard")
                        st.plotly_chart(figu, use_container_width=True)

                        tmp = std.copy()
                        tmp["date"] = pd.to_datetime(tmp["date"]).dt.to_period("M").dt.to_timestamp()
                        agg = tmp.groupby(["date", "group"], as_index=False)["value"].mean()
                        figb = px.bar(agg, x="date", y="value", color="group", title="ì›” í‰ê·  ë§‰ëŒ€")
                        if FONT_FAMILY:
                            figb.update_layout(font_family="Pretendard")
                        st.plotly_chart(figb, use_container_width=True)

                    except Exception as e:
                        st.error(f"CSV íŒŒì‹± ì‹¤íŒ¨: {e}")
            else:
                st.info("CSVê°€ ë³´ì´ì§€ ì•Šìœ¼ë©´ ë°ì´í„°ì…‹ ìŠ¬ëŸ¬ê·¸ë¥¼ í™•ì¸í•˜ê³  ë‹¤ì‹œ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”.")

# ---------- ê²°ë¡  (ì œì–¸) ----------
st.markdown("## ê²°ë¡  (ì œì–¸)")
st.markdown(
    """
ì´ë²ˆ ì—°êµ¬ë¥¼ í†µí•´ ìš°ë¦¬ëŠ” ê¸°ì˜¨ ìƒìŠ¹ì´ ë‹¨ìˆœíˆ ìƒí™œ ë¶ˆí¸ì— ê·¸ì¹˜ì§€ ì•Šê³ , í•™ìƒë“¤ì˜ ìˆ˜ë©´ ì§ˆ ì €í•˜ì™€ ì§‘ì¤‘ë ¥ ê°ì†Œë¥¼ ì´ˆë˜í•˜ë©°, í•™ì—… ì„±ì·¨ë„ì— ë¶€ì •ì ì¸ ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆìŒì„ í™•ì¸í•˜ì˜€ë‹¤. íŠ¹íˆ ê¸°ì˜¨ì´ ì¼ì • ìˆ˜ì¤€ ì´ìƒ ìƒìŠ¹í•  ê²½ìš° ì„±ì ì´ í‘œì¤€í¸ì°¨ ë‹¨ìœ„ë¡œ ê°ì†Œí•˜ëŠ” ê²½í–¥ì´ ì—¬ëŸ¬ ì—°êµ¬ì—ì„œ ê³µí†µì ìœ¼ë¡œ ë“œëŸ¬ë‚¬ë‹¤. ì´ëŠ” ë‹¨ì¼ ìš”ì¸ì´ ì•„ë‹Œ, ë°˜ë³µì ì´ê³  ëˆ„ì ëœ ë†’ì€ ì˜¨ë„ ë…¸ì¶œì´ ì¥ê¸°ì ìœ¼ë¡œ í•™ìƒë“¤ì˜ í•™ìŠµ ëŠ¥ë ¥ì„ ì €í•´í•œë‹¤ëŠ” ì ì„ ë³´ì—¬ì¤€ë‹¤.
"""
)

# ---------- í•˜ë‹¨ ì •ë³´ ----------
st.markdown("---")
st.caption(
    "ë³¸ ì•±ì€ ê³µê°œ ë°ì´í„° ì‹¤íŒ¨ ì‹œ ì˜ˆì‹œ ë°ì´í„°ë¡œ ìë™ ëŒ€ì²´í•˜ë©°, ì˜ˆì‹œ ë°ì´í„°ëŠ” ì—°êµ¬/ì •ì±… íŒë‹¨ì— ë¶€ì í•©í•©ë‹ˆë‹¤. "
    "PISA ë°ì´í„°ëŠ” World Bank EdStats API ê°€ìš©ì„±ì— ë”°ë¼ êµ­ê°€Â·ì—°ë„ë³„ ê³µë°±ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
)
